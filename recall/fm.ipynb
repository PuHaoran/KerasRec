{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "93aeee37",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import faiss\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import namedtuple\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.models import *\n",
    "from tensorflow.python.keras.callbacks import EarlyStopping\n",
    "from sklearn.preprocessing import  MinMaxScaler, LabelEncoder\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.metrics import classification_report, roc_curve\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f166b6c3",
   "metadata": {},
   "source": [
    "##### 获取数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1fc3cf82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train.shape: (1956191, 14), test.shape: (12078, 14)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>hist_item_id</th>\n",
       "      <th>hist_s1</th>\n",
       "      <th>hist_s2</th>\n",
       "      <th>item_id</th>\n",
       "      <th>label</th>\n",
       "      <th>rating</th>\n",
       "      <th>click_timestamp</th>\n",
       "      <th>hist_len</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>item_date</th>\n",
       "      <th>item_title</th>\n",
       "      <th>item_cate_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>586323</th>\n",
       "      <td>3163</td>\n",
       "      <td>2078,1991,3194,2079,2342,3217,3073,2052,2874,3...</td>\n",
       "      <td>1863,1005,1007,1945,2065,1355,2460,2026,2402,1...</td>\n",
       "      <td>1256,1899,1059,2093,1937,1356,2848,1978,2573,6...</td>\n",
       "      <td>785</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>75</td>\n",
       "      <td>1497,1498,1499,0,0,0,0,0,0,0,0,0,0,0,0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78079</th>\n",
       "      <td>5677</td>\n",
       "      <td>52,1815,1483,2234,1727,11,2603,594,1654,536,14...</td>\n",
       "      <td>1879,1598,1190,235,1187,1272,10,725,574,1059,0...</td>\n",
       "      <td>2285,1932,1228,3616,1373,3040,1288,25,1246,353...</td>\n",
       "      <td>589</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>958955726</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>70</td>\n",
       "      <td>346,0,0,0,0,0,0,0,0,0,0,0,0,0,0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136688</th>\n",
       "      <td>5510</td>\n",
       "      <td>2210,1193,3181,2355,1368,2642,258,1179,1204,84...</td>\n",
       "      <td>2461,346,1256,1938,1990,2047,2848,1567,771,259...</td>\n",
       "      <td>1569,471,377,2880,1356,1932,1205,3188,477,589,...</td>\n",
       "      <td>2091</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>71</td>\n",
       "      <td>3180,2374,11,65,1015,1066,0,0,0,0,0,0,0,0,0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>766291</th>\n",
       "      <td>3900</td>\n",
       "      <td>429,2724,1076,1009,1503,2405,2301,88,3,2490,21...</td>\n",
       "      <td>3200,3323,2731,1361,912,316,1877,590,2736,1196...</td>\n",
       "      <td>3180,2506,3324,3772,651,1491,19,2312,2313,2315...</td>\n",
       "      <td>36</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>965877433</td>\n",
       "      <td>50</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>76</td>\n",
       "      <td>28,78,79,0,0,0,0,0,0,0,0,0,0,0,0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12050</th>\n",
       "      <td>2800</td>\n",
       "      <td>590,2014,3033,69,848,2790,3683,3117,3287,3445,...</td>\n",
       "      <td>1974,2200,2253,104,550,1386,2363,477,594,2735,...</td>\n",
       "      <td>605,1246,3052,3079,3087,377,1673,1727,2694,62,...</td>\n",
       "      <td>1808</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>79</td>\n",
       "      <td>2754,2871,0,0,0,0,0,0,0,0,0,0,0,0,0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        user_id                                       hist_item_id  \\\n",
       "586323     3163  2078,1991,3194,2079,2342,3217,3073,2052,2874,3...   \n",
       "78079      5677  52,1815,1483,2234,1727,11,2603,594,1654,536,14...   \n",
       "136688     5510  2210,1193,3181,2355,1368,2642,258,1179,1204,84...   \n",
       "766291     3900  429,2724,1076,1009,1503,2405,2301,88,3,2490,21...   \n",
       "12050      2800  590,2014,3033,69,848,2790,3683,3117,3287,3445,...   \n",
       "\n",
       "                                                  hist_s1  \\\n",
       "586323  1863,1005,1007,1945,2065,1355,2460,2026,2402,1...   \n",
       "78079   1879,1598,1190,235,1187,1272,10,725,574,1059,0...   \n",
       "136688  2461,346,1256,1938,1990,2047,2848,1567,771,259...   \n",
       "766291  3200,3323,2731,1361,912,316,1877,590,2736,1196...   \n",
       "12050   1974,2200,2253,104,550,1386,2363,477,594,2735,...   \n",
       "\n",
       "                                                  hist_s2  item_id  label  \\\n",
       "586323  1256,1899,1059,2093,1937,1356,2848,1978,2573,6...      785      0   \n",
       "78079   2285,1932,1228,3616,1373,3040,1288,25,1246,353...      589      1   \n",
       "136688  1569,471,377,2880,1356,1932,1205,3188,477,589,...     2091      0   \n",
       "766291  3180,2506,3324,3772,651,1491,19,2312,2313,2315...       36      1   \n",
       "12050   605,1246,3052,3079,3087,377,1673,1727,2694,62,...     1808      0   \n",
       "\n",
       "        rating  click_timestamp  hist_len  gender  age  item_date  \\\n",
       "586323       0                0        50       1    2         75   \n",
       "78079        2        958955726        50       1    3         70   \n",
       "136688       0                0        42       1    2         71   \n",
       "766291       5        965877433        50       2    3         76   \n",
       "12050        0                0        50       2    2         79   \n",
       "\n",
       "                                         item_title  item_cate_id  \n",
       "586323       1497,1498,1499,0,0,0,0,0,0,0,0,0,0,0,0             5  \n",
       "78079               346,0,0,0,0,0,0,0,0,0,0,0,0,0,0             1  \n",
       "136688  3180,2374,11,65,1015,1066,0,0,0,0,0,0,0,0,0             6  \n",
       "766291             28,78,79,0,0,0,0,0,0,0,0,0,0,0,0             8  \n",
       "12050           2754,2871,0,0,0,0,0,0,0,0,0,0,0,0,0             1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_csv('../data/ml-1m/train_df.csv')\n",
    "test_df = pd.read_csv('../data/ml-1m/test_df.csv')\n",
    "train_df = train_df.sample(frac=1.0)\n",
    "data = train_df.append(test_df)\n",
    "print('train.shape: {}, test.shape: {}'.format(train_df.shape, test_df.shape))\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c56c3aa",
   "metadata": {},
   "source": [
    "##### 模型构建\n",
    "\n",
    "用户侧\n",
    "\n",
    "- 用户ID\n",
    "- 性别\n",
    "- 年龄\n",
    "- 序列长度\n",
    "- 序列物品ID\n",
    "\n",
    "物品侧\n",
    "\n",
    "- 物品ID\n",
    "- 物品类别ID\n",
    "\n",
    "提取预训练embedding向量，例如提取user侧embedding向量。\n",
    "\n",
    "1. 构建一个完整的模型结构。\n",
    "2. 将用户/物品侧输入和输出张量作为模型属性。\n",
    "3. 实例化一个新Model，选取用户输入输出，输入为用户Input层特征，输出为用户embedding向量。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "80ccbbce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([SparseFeature(name='user_id', vocabulary_size=6041, embedding_size=4),\n",
       "  SparseFeature(name='gender', vocabulary_size=3, embedding_size=4),\n",
       "  SparseFeature(name='age', vocabulary_size=8, embedding_size=4),\n",
       "  DenseFeature(name='hist_len', dimension=1),\n",
       "  VarLenSparseFeature(name='hist_item_id', vocabulary_size=3884, embedding_size=4, maxlen=50)],\n",
       " [SparseFeature(name='item_id', vocabulary_size=3884, embedding_size=4),\n",
       "  SparseFeature(name='item_cate_id', vocabulary_size=19, embedding_size=4)])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SparseFeature = namedtuple('SparseFeature', ['name', 'vocabulary_size', 'embedding_size'])\n",
    "DenseFeature = namedtuple('DenseFeature', ['name', 'dimension'])\n",
    "VarLenSparseFeature = namedtuple('VarLenSparseFeature', ['name', 'vocabulary_size', 'embedding_size', 'maxlen'])\n",
    "\n",
    "user_feature_columns = [\n",
    "    SparseFeature('user_id', data.user_id.max()+1, embedding_size=4),\n",
    "    SparseFeature('gender', data.gender.max()+1, embedding_size=4),\n",
    "    SparseFeature('age', data.age.max()+1, embedding_size=4),\n",
    "    DenseFeature('hist_len', 1),\n",
    "    VarLenSparseFeature('hist_item_id', data.item_id.max()+1, embedding_size=4, maxlen=50)\n",
    "]\n",
    "item_feature_columns = [\n",
    "    SparseFeature('item_id', data.item_id.max()+1, embedding_size=4),\n",
    "    SparseFeature('item_cate_id', data.item_cate_id.max()+1, embedding_size=4),\n",
    "]\n",
    "user_feature_columns, item_feature_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ea3c28eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hidden_units:  [4]\n",
      "hidden_units:  [4]\n",
      "Model: \"model_9\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "user_id (InputLayer)            [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "gender (InputLayer)             [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "age (InputLayer)                [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "item_id (InputLayer)            [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "item_cate_id (InputLayer)       [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "emb_user_id (Embedding)         (None, 1, 4)         24168       user_id[0][0]                    \n",
      "                                                                 user_id[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "emb_gender (Embedding)          (None, 1, 4)         16          gender[0][0]                     \n",
      "                                                                 gender[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "emb_age (Embedding)             (None, 1, 4)         36          age[0][0]                        \n",
      "                                                                 age[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "emb_item_id (Embedding)         (None, 1, 4)         15540       item_id[0][0]                    \n",
      "                                                                 item_id[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "emb_item_cate_id (Embedding)    (None, 1, 4)         80          item_cate_id[0][0]               \n",
      "                                                                 item_cate_id[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_12 (Concatenate)    (None, 3, 4)         0           emb_user_id[1][0]                \n",
      "                                                                 emb_gender[1][0]                 \n",
      "                                                                 emb_age[1][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_14 (Concatenate)    (None, 2, 4)         0           emb_item_id[1][0]                \n",
      "                                                                 emb_item_cate_id[1][0]           \n",
      "__________________________________________________________________________________________________\n",
      "hist_len (InputLayer)           [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_15 (Flatten)            (None, 4)            0           emb_user_id[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "flatten_16 (Flatten)            (None, 4)            0           emb_gender[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "flatten_17 (Flatten)            (None, 4)            0           emb_age[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bi_interaction_pooling_6 (BiInt (None, 4)            0           concatenate_12[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "flatten_18 (Flatten)            (None, 4)            0           emb_item_id[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "flatten_19 (Flatten)            (None, 4)            0           emb_item_cate_id[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "bi_interaction_pooling_7 (BiInt (None, 4)            0           concatenate_14[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_13 (Concatenate)    (None, 17)           0           hist_len[0][0]                   \n",
      "                                                                 flatten_15[0][0]                 \n",
      "                                                                 flatten_16[0][0]                 \n",
      "                                                                 flatten_17[0][0]                 \n",
      "                                                                 bi_interaction_pooling_6[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_15 (Concatenate)    (None, 12)           0           flatten_18[0][0]                 \n",
      "                                                                 flatten_19[0][0]                 \n",
      "                                                                 bi_interaction_pooling_7[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "dense_11 (Dense)                (None, 4)            72          concatenate_13[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_12 (Dense)                (None, 4)            52          concatenate_15[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_8 (Dropout)             (None, 4)            0           dense_11[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_9 (Dropout)             (None, 4)            0           dense_12[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "similarity_3 (Similarity)       (None, 1)            0           dropout_8[0][0]                  \n",
      "                                                                 dropout_9[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_13 (Dense)                (None, 1)            2           similarity_3[0][0]               \n",
      "==================================================================================================\n",
      "Total params: 39,966\n",
      "Trainable params: 39,966\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def model_metric(prob, label, thr=0.5):\n",
    "    \"\"\" 模型评估 \"\"\"\n",
    "    # AUC\n",
    "    fpr, tpr, threshold = metrics.roc_curve(label, prob)\n",
    "    auc = metrics.auc(fpr, tpr)\n",
    "    score = metrics.accuracy_score(label, prob > thr)\n",
    "    # LogLoss\n",
    "    logloss = log_loss(label, prob)\n",
    "    print('模型准确率:{}, AUC得分:{}, LogLoss:{}'.format(score, auc, logloss))\n",
    "    print(classification_report(label, prob > thr, digits=2))\n",
    "    print('==========================================================')\n",
    "\n",
    "def build_input_layers(feature_columns):\n",
    "    \"\"\" 构建输入层 \"\"\"\n",
    "    dense_input_dict, sparse_input_dict, varlen_sparse_input_dict = {}, {}, {}\n",
    "    for f in feature_columns:\n",
    "        if isinstance(f, DenseFeature):\n",
    "            dense_input_dict[f.name] = Input(shape=(f.dimension, ), name=f.name)\n",
    "        elif isinstance(f, SparseFeature):\n",
    "            sparse_input_dict[f.name] = Input(shape=(1, ), name=f.name)\n",
    "        elif isinstance(f, VarLenSparseFeature):\n",
    "            varlen_sparse_input_dict[f.name] = Input(shape=(f.maxlen, ), name=f.name)\n",
    "    return dense_input_dict, sparse_input_dict, varlen_sparse_input_dict\n",
    "\n",
    "def concat_input_list(input_list):\n",
    "    \"\"\" 合并input列表 \"\"\"\n",
    "    _num = len(input_list)\n",
    "    if _num > 1:\n",
    "        return Concatenate(axis=1)(input_list)\n",
    "    elif len(input_list) == 1:\n",
    "        return input_list[0]\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def build_embedding_layers(feature_columns):\n",
    "    \"\"\" 构建embedding层 \"\"\"\n",
    "    embedding_layer_dict = {}\n",
    "    for f in feature_columns:\n",
    "        if isinstance(f, SparseFeature):\n",
    "            embedding_layer_dict[f.name] = Embedding(f.vocabulary_size+1, f.embedding_size, name='emb_' + f.name)\n",
    "        elif isinstance(f, VarLenSparseFeature):\n",
    "            embedding_layer_dict[f.name] = Embedding(f.vocabulary_size+1, f.embedding_size, name='var_emb_' + f.name, mask_zero=True)\n",
    "    return embedding_layer_dict\n",
    "    \n",
    "def embedding_lookup(columns, input_dict, embedding_layer_dict, flatten=False):\n",
    "    \"\"\" 根据feature_columns或column_names查表，得到对应embedding向量列表 \"\"\"\n",
    "    embedding_list = []\n",
    "    for f in columns:\n",
    "        if type(f) == str:\n",
    "            column_name = f\n",
    "        else:\n",
    "            column_name = f.name\n",
    "        _input = input_dict[column_name]\n",
    "        _embed = embedding_layer_dict[column_name]\n",
    "        embed_layer = _embed(_input)\n",
    "        if flatten:\n",
    "            embed_layer = Flatten()(embed_layer)\n",
    "        embedding_list.append(embed_layer)\n",
    "    return embedding_list\n",
    "    \n",
    "def get_dnn(dnn_input, hidden_units=[64, 32], activation='relu', l2=0.01):\n",
    "    print('hidden_units: ', hidden_units)\n",
    "    dnn_list = [Dense(unit, activation=activation, kernel_regularizer=tf.keras.regularizers.l2(l2=l2)) for unit in hidden_units]\n",
    "    dnn_out = dnn_input\n",
    "    for dnn in dnn_list:\n",
    "        dnn_out = Dropout(0.5)(dnn(dnn_out)) # dnn(dnn_out)\n",
    "    return dnn_out\n",
    "\n",
    "class Similarity(Layer):\n",
    "    def __init__(self, gamma=1, similarity_type='cosine'):\n",
    "        super(Similarity, self).__init__()\n",
    "        self.gamma = 1\n",
    "        self.similarity_type = similarity_type\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        query, candidate = inputs\n",
    "        if self.similarity_type == 'cosine':\n",
    "            score = tf.reduce_sum(tf.multiply(query, candidate), -1, keepdims=True) # 点积\n",
    "            norm_query = tf.norm(query, axis=-1, keepdims=True) \n",
    "            norm_candidate = tf.norm(candidate, axis=-1, keepdims=True)\n",
    "            score = tf.divide(score, norm_query * norm_candidate + 1e-8)\n",
    "        elif self.similarity_type == 'inner_product':\n",
    "            score = tf.reduce_sum(tf.multiply(query, candidate), -1, keepdims=True) # 点积\n",
    "        else:\n",
    "            raise Exception(\"similarity_type error\")\n",
    "        return score\n",
    "    \n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return (None, 1)\n",
    "\n",
    "class BiInteractionPooling(Layer):\n",
    "    \"\"\" embedding向量集合两两点乘(对应位置相乘)后相加 \"\"\"\n",
    "    def __init__(self):\n",
    "        super(BiInteractionPooling, self).__init__()\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        concat_embed_values = inputs\n",
    "        #print('concat_embed_values.shape: ', concat_embed_values.shape) # (None, 26, 4)\n",
    "        sum_square = tf.square(tf.reduce_sum(concat_embed_values, axis=1, keepdims=False)) # (None, 4)\n",
    "        #print('sum_square.shape: ', sum_square.shape)\n",
    "        square_sum = tf.reduce_sum(concat_embed_values * concat_embed_values, axis=1, keepdims=False) # (None, 4)\n",
    "        #print('square_sum.shape: ', square_sum.shape)\n",
    "        output = 0.5*(sum_square - square_sum) # 和的平方-平方的和 (None, 4)\n",
    "        return output\n",
    "    \n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return (None, input_shape[2])\n",
    "\n",
    "def build_bi_interaction_pooling_layers(sparse_input_dict, sparse_feature_columns, embedding_layer_dict):\n",
    "    sparse_kd_embed_list = []\n",
    "    for f in sparse_feature_columns:\n",
    "        _input = sparse_input_dict[f.name] \n",
    "        _embed = embedding_layer_dict[f.name]\n",
    "        embed_layer = _embed(_input)\n",
    "        sparse_kd_embed_list.append(embed_layer)\n",
    "    #print('sparse_kd_embed_list: ', sparse_kd_embed_list)\n",
    "    concat_sparse_kd_embed = Concatenate(axis=1)(sparse_kd_embed_list)\n",
    "    pooling_out = BiInteractionPooling()(concat_sparse_kd_embed)\n",
    "    return pooling_out\n",
    "    \n",
    "def FM(user_feature_columns,\n",
    "       item_feature_columns,\n",
    "       user_dnn_hidden_units=[8, 4],\n",
    "       item_dnn_hidden_units=[8, 4],\n",
    "       dnn_activation='relu',\n",
    "       l2=0.01,\n",
    "       dnn_dropout=0.5):\n",
    "    \"\"\" Deep Structured Semantic Model \"\"\"\n",
    "    user_dense_input_dict, user_sparse_input_dict, _ = build_input_layers(user_feature_columns)\n",
    "    item_dense_input_dict, item_sparse_input_dict, _ = build_input_layers(item_feature_columns)\n",
    "    \n",
    "    # user/item Input\n",
    "    user_input_list = list(user_dense_input_dict.values()) + list(user_sparse_input_dict.values())\n",
    "    item_input_list = list(item_dense_input_dict.values()) + list(item_sparse_input_dict.values())\n",
    "\n",
    "    # 用户侧 concat(dense feature: input + sparse feature: input->flatten embed->concat + fm embedding feature) =》DNN =》user_embedding\n",
    "    user_dense_input_list = list(user_dense_input_dict.values())\n",
    "    user_embedding_layer_dict = build_embedding_layers(user_feature_columns)\n",
    "    user_sparse_feature_columns = list(filter(lambda x: isinstance(x, SparseFeature), user_feature_columns))\n",
    "    flatten_user_sparse_embed_list = embedding_lookup(user_sparse_feature_columns, user_sparse_input_dict, user_embedding_layer_dict, flatten=True)\n",
    "    user_bi_pooling_out = build_bi_interaction_pooling_layers(user_sparse_input_dict, user_sparse_feature_columns, user_embedding_layer_dict)\n",
    "    user_dnn_input = concat_input_list(user_dense_input_list + flatten_user_sparse_embed_list + [user_bi_pooling_out])\n",
    "    user_dnn_out = get_dnn(user_dnn_input, hidden_units=user_dnn_hidden_units)\n",
    "\n",
    "    # 物品侧 concat(dense feature: input + sparse feature: input->flatten embed->concat + fm embedding feature) =》DNN =》item_embedding\n",
    "    item_dense_input_list = list(item_dense_input_dict.values())\n",
    "    item_embedding_layer_dict = build_embedding_layers(item_feature_columns)\n",
    "    item_sparse_feature_columns = list(filter(lambda x: isinstance(x, SparseFeature), item_feature_columns))\n",
    "    flatten_item_sparse_embed_list = embedding_lookup(item_sparse_feature_columns, item_sparse_input_dict, item_embedding_layer_dict, flatten=True)\n",
    "    item_bi_pooling_out = build_bi_interaction_pooling_layers(item_sparse_input_dict, item_sparse_feature_columns, item_embedding_layer_dict)\n",
    "    item_dnn_input = concat_input_list(item_dense_input_list + flatten_item_sparse_embed_list + [item_bi_pooling_out])\n",
    "    item_dnn_out = get_dnn(item_dnn_input, hidden_units=item_dnn_hidden_units)\n",
    "    \n",
    "    # cosine inner_product\n",
    "    score = Similarity()([user_dnn_out, item_dnn_out]) # (None, 1)\n",
    "    \n",
    "    output_layer = Dense(1, activation='sigmoid')(score)\n",
    "    model = Model(user_input_list+item_input_list, output_layer)\n",
    "    \n",
    "    model.__setattr__(\"user_input\", user_input_list)\n",
    "    model.__setattr__(\"item_input\", item_input_list)\n",
    "    model.__setattr__(\"user_embedding\", user_dnn_out)\n",
    "    model.__setattr__(\"item_embedding\", item_dnn_out)\n",
    "    \n",
    "    user_embed_model = Model(inputs=model.user_input, outputs=model.user_embedding)\n",
    "    item_embed_model = Model(inputs=model.item_input, outputs=model.item_embedding)\n",
    "    return model, user_embed_model, item_embed_model\n",
    "\n",
    "model, user_embed_model, item_embed_model = FM(user_feature_columns,\n",
    "                                                 item_feature_columns, \n",
    "                                                 user_dnn_hidden_units=[4],\n",
    "                                                 item_dnn_hidden_units=[4])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c9a5c3d",
   "metadata": {},
   "source": [
    "##### 模型训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "368cf77e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_input = {\n",
    "    'user_id': np.array(train_df['user_id']),\n",
    "    'gender': np.array(train_df['gender']),\n",
    "    'age': np.array(train_df['age']),\n",
    "    'item_id': np.array(train_df['item_id']),\n",
    "    'item_cate_id': np.array(train_df['item_cate_id']),\n",
    "    'item_date': np.array(train_df['item_date']),\n",
    "    'hist_item_id': np.array([[int(i) for i in s.split(',')] for s in train_df['hist_item_id']]),\n",
    "    'hist_len': np.array(train_df['hist_len']),\n",
    "}\n",
    "test_input = {\n",
    "    'user_id': np.array(test_df['user_id']),\n",
    "    'gender': np.array(test_df['gender']),\n",
    "    'age': np.array(test_df['age']),\n",
    "    'item_id': np.array(test_df['item_id']),\n",
    "    'item_cate_id': np.array(test_df['item_cate_id']),\n",
    "    'item_date': np.array(test_df['item_date']),\n",
    "    'hist_item_id': np.array([[int(i) for i in s.split(',')] for s in test_df['hist_item_id']]),\n",
    "    'hist_len': np.array(test_df['hist_len']),\n",
    "}\n",
    "# 用户表\n",
    "user_input = {\n",
    "    'user_id': np.array(test_df[test_df.label == 1]['user_id']),\n",
    "    'gender': np.array(test_df[test_df.label == 1]['gender']),\n",
    "    'age': np.array(test_df[test_df.label == 1]['age']),\n",
    "    'hist_item_id': np.array([[int(i) for i in s.split(',')] for s in test_df[test_df.label == 1]['hist_item_id']]),\n",
    "    'hist_len': np.array(test_df[test_df.label == 1]['hist_len']),\n",
    "}\n",
    "# 物品表\n",
    "item_df = data[['item_id', 'item_cate_id', 'item_date']].drop_duplicates(['item_id'])\n",
    "item_input = {\n",
    "    'item_id': np.array(item_df['item_id']),\n",
    "    'item_cate_id': np.array(item_df['item_cate_id']),\n",
    "    'item_date': np.array(item_df['item_date']),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "212c4981",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1529/1529 [==============================] - 6s 2ms/step - loss: 0.6911 - binary_crossentropy: 0.6752 - auc: 0.5676 - val_loss: 0.6050 - val_binary_crossentropy: 0.6044 - val_auc: 0.7187\n",
      "Epoch 2/100\n",
      "1529/1529 [==============================] - 3s 2ms/step - loss: 0.6587 - binary_crossentropy: 0.6583 - auc: 0.6005 - val_loss: 0.5784 - val_binary_crossentropy: 0.5781 - val_auc: 0.7723\n",
      "Epoch 3/100\n",
      "1529/1529 [==============================] - 4s 2ms/step - loss: 0.6547 - binary_crossentropy: 0.6544 - auc: 0.6092 - val_loss: 0.5834 - val_binary_crossentropy: 0.5827 - val_auc: 0.7758\n",
      "Epoch 4/100\n",
      "1529/1529 [==============================] - 4s 2ms/step - loss: 0.6699 - binary_crossentropy: 0.6695 - auc: 0.5647 - val_loss: 0.5864 - val_binary_crossentropy: 0.5863 - val_auc: 0.7837\n",
      "Epoch 5/100\n",
      "1529/1529 [==============================] - 4s 2ms/step - loss: 0.6701 - binary_crossentropy: 0.6699 - auc: 0.5585 - val_loss: 0.5890 - val_binary_crossentropy: 0.5888 - val_auc: 0.7579\n",
      "Epoch 6/100\n",
      "1529/1529 [==============================] - 4s 2ms/step - loss: 0.6694 - binary_crossentropy: 0.6692 - auc: 0.5645 - val_loss: 0.5825 - val_binary_crossentropy: 0.5824 - val_auc: 0.7901\n",
      "Epoch 7/100\n",
      "1529/1529 [==============================] - 4s 2ms/step - loss: 0.6689 - binary_crossentropy: 0.6687 - auc: 0.5653 - val_loss: 0.5824 - val_binary_crossentropy: 0.5823 - val_auc: 0.7870\n",
      "Epoch 8/100\n",
      "1529/1529 [==============================] - 4s 2ms/step - loss: 0.6694 - binary_crossentropy: 0.6692 - auc: 0.5654 - val_loss: 0.5838 - val_binary_crossentropy: 0.5836 - val_auc: 0.7848: 0.6695 - binary_crossentropy: 0.6693 -\n",
      "Epoch 9/100\n",
      "1529/1529 [==============================] - 4s 3ms/step - loss: 0.6693 - binary_crossentropy: 0.6692 - auc: 0.5654 - val_loss: 0.5832 - val_binary_crossentropy: 0.5830 - val_auc: 0.7908\n",
      "Epoch 10/100\n",
      "1529/1529 [==============================] - 5s 3ms/step - loss: 0.6691 - binary_crossentropy: 0.6690 - auc: 0.5661 - val_loss: 0.5820 - val_binary_crossentropy: 0.5819 - val_auc: 0.7913\n",
      "Epoch 11/100\n",
      "1529/1529 [==============================] - 5s 3ms/step - loss: 0.6688 - binary_crossentropy: 0.6687 - auc: 0.5672 - val_loss: 0.5824 - val_binary_crossentropy: 0.5823 - val_auc: 0.7966\n",
      "Epoch 12/100\n",
      "1529/1529 [==============================] - 5s 3ms/step - loss: 0.6689 - binary_crossentropy: 0.6688 - auc: 0.5672 - val_loss: 0.5806 - val_binary_crossentropy: 0.5806 - val_auc: 0.7974\n",
      "Epoch 00012: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x15de96782e8>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 模型训练\n",
    "my_callbacks = [\n",
    "    EarlyStopping(monitor='val_loss', patience=10, verbose=2, mode='auto')\n",
    "]\n",
    "model.compile('adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=[\"binary_crossentropy\", tf.keras.metrics.AUC(name='auc')])\n",
    "model.fit(train_input,\n",
    "          train_df['label'].values,\n",
    "          batch_size=1024,\n",
    "          epochs=100,\n",
    "          validation_split=0.2,\n",
    "          callbacks=my_callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "19f9da86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "模型准确率:0.7279350885908263, AUC得分:0.7567515969500009, LogLoss:0.6069906781837628\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.76      0.74      6038\n",
      "           1       0.74      0.70      0.72      6040\n",
      "\n",
      "    accuracy                           0.73     12078\n",
      "   macro avg       0.73      0.73      0.73     12078\n",
      "weighted avg       0.73      0.73      0.73     12078\n",
      "\n",
      "==========================================================\n"
     ]
    }
   ],
   "source": [
    "# 模型预测与评估\n",
    "result = model.predict(test_input)\n",
    "model_metric(np.array([i[0] for i in result]), test_df['label'].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ddf76dc",
   "metadata": {},
   "source": [
    "##### Embedding召回\n",
    "\n",
    "① 提取user和item embedding向量。\n",
    "\n",
    "② 构建faiss索引求用户TopN相似物品。\n",
    "\n",
    "③ 评估召回率和hit rate。\n",
    "\n",
    "④ 保存用户、物品向量到本地。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c1762e5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c37779b4a42428fa83fb3e7db35d533",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recall:  0.07781456953642384\n"
     ]
    }
   ],
   "source": [
    "def get_recall(true_y, pred_y, top_n=50):\n",
    "    \"\"\" 召回率 \"\"\"\n",
    "    return len(set(pred_y[:top_n])&set(true_y)) * 1.0 / len(true_y)\n",
    "\n",
    "# 1. 提取embedding向量。\n",
    "user_embeddings = user_embed_model.predict(user_input, batch_size=2**12)\n",
    "item_embeddings = item_embed_model.predict(item_input, batch_size=2**12)\n",
    "test_user_item_dict = test_df[test_df.label == 1][['user_id', 'item_id']].set_index('user_id').item_id.to_dict()\n",
    "\n",
    "# 2. faiss求TopN相似物品。\n",
    "embedding_size = 4\n",
    "index = faiss.IndexFlatIP(embedding_size)\n",
    "index.add(item_embeddings)\n",
    "D, I = index.search(np.ascontiguousarray(user_embeddings), 50)\n",
    "\n",
    "# 3. 评估召回率和hit rate。\n",
    "hit = 0\n",
    "recall_list = []\n",
    "for i, uid in tqdm(enumerate(user_input['user_id'])):\n",
    "    preds = [item_df['item_id'].values[j] for j in I[i]]\n",
    "    recall = get_recall([test_user_item_dict[uid]], preds, top_n=50)\n",
    "    recall_list.append(recall)\n",
    "    if test_user_item_dict[uid] in preds:\n",
    "        hit += 1\n",
    "\n",
    "print('recall: ', np.mean(recall_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6ca5593",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
