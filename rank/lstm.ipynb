{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4407c118",
   "metadata": {},
   "source": [
    "## LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b3224258",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import namedtuple\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.models import *\n",
    "from tensorflow.python.keras.callbacks import EarlyStopping\n",
    "from sklearn.preprocessing import  MinMaxScaler, LabelEncoder\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.metrics import classification_report, roc_curve\n",
    "\n",
    "from keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9d1f3f0",
   "metadata": {},
   "source": [
    "##### 获取数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d39a4c28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_df.shape: (1956191, 14), test_df.shape: (12078, 14)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>hist_item_id</th>\n",
       "      <th>hist_s1</th>\n",
       "      <th>hist_s2</th>\n",
       "      <th>item_id</th>\n",
       "      <th>label</th>\n",
       "      <th>rating</th>\n",
       "      <th>click_timestamp</th>\n",
       "      <th>hist_len</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>item_date</th>\n",
       "      <th>item_title</th>\n",
       "      <th>item_cate_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1741</td>\n",
       "      <td>2904,2008,230,1169,2064,3475,1952,1228,943,275...</td>\n",
       "      <td>898,948,3022,1888,2891,1080,2204,618,1372,852,...</td>\n",
       "      <td>3722,1244,3023,1594,3348,288,323,36,1226,1254,...</td>\n",
       "      <td>3266</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>974711543</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>29</td>\n",
       "      <td>4566,4567,0,0,0,0,0,0,0,0,0,0,0,0,0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1880</td>\n",
       "      <td>1280,1213,1075,1274,1135,3292,2902,2008,3000,3...</td>\n",
       "      <td>3410,2666,3723,1109,2046,2078,1891,3639,2874,2...</td>\n",
       "      <td>3101,2671,1271,2406,3616,1158,2483,2858,2861,2...</td>\n",
       "      <td>3266</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>29</td>\n",
       "      <td>4566,4567,0,0,0,0,0,0,0,0,0,0,0,0,0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3292</td>\n",
       "      <td>1895,1016,2030,2981,3008,2068,998,1002,1006,28...</td>\n",
       "      <td>3438,1948,3692,1963,1964,1178,1360,2134,3027,2...</td>\n",
       "      <td>2171,2972,3031,3176,1110,2041,2711,1059,3554,3...</td>\n",
       "      <td>3266</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>968098376</td>\n",
       "      <td>50</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>29</td>\n",
       "      <td>4566,4567,0,0,0,0,0,0,0,0,0,0,0,0,0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>566</td>\n",
       "      <td>2789,2069,1013,613,3657,3677,774,1965,3219,164...</td>\n",
       "      <td>1248,590,897,605,2118,2694,110,3483,2751,1024,...</td>\n",
       "      <td>1644,643,3377,1557,1599,2058,159,2270,50,1074,...</td>\n",
       "      <td>3266</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>976210413</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>29</td>\n",
       "      <td>4566,4567,0,0,0,0,0,0,0,0,0,0,0,0,0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1088</td>\n",
       "      <td>52,1394,2851,2643,2909,416,1665,733,984,2266,1...</td>\n",
       "      <td>1233,2772,1815,539,3431,2761,838,1225,11,3029,...</td>\n",
       "      <td>2703,886,1253,1261,2365,3087,941,305,3061,711,...</td>\n",
       "      <td>3266</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1023534057</td>\n",
       "      <td>50</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>29</td>\n",
       "      <td>4566,4567,0,0,0,0,0,0,0,0,0,0,0,0,0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id                                       hist_item_id  \\\n",
       "0     1741  2904,2008,230,1169,2064,3475,1952,1228,943,275...   \n",
       "1     1880  1280,1213,1075,1274,1135,3292,2902,2008,3000,3...   \n",
       "2     3292  1895,1016,2030,2981,3008,2068,998,1002,1006,28...   \n",
       "3      566  2789,2069,1013,613,3657,3677,774,1965,3219,164...   \n",
       "4     1088  52,1394,2851,2643,2909,416,1665,733,984,2266,1...   \n",
       "\n",
       "                                             hist_s1  \\\n",
       "0  898,948,3022,1888,2891,1080,2204,618,1372,852,...   \n",
       "1  3410,2666,3723,1109,2046,2078,1891,3639,2874,2...   \n",
       "2  3438,1948,3692,1963,1964,1178,1360,2134,3027,2...   \n",
       "3  1248,590,897,605,2118,2694,110,3483,2751,1024,...   \n",
       "4  1233,2772,1815,539,3431,2761,838,1225,11,3029,...   \n",
       "\n",
       "                                             hist_s2  item_id  label  rating  \\\n",
       "0  3722,1244,3023,1594,3348,288,323,36,1226,1254,...     3266      1       4   \n",
       "1  3101,2671,1271,2406,3616,1158,2483,2858,2861,2...     3266      0       0   \n",
       "2  2171,2972,3031,3176,1110,2041,2711,1059,3554,3...     3266      1       5   \n",
       "3  1644,643,3377,1557,1599,2058,159,2270,50,1074,...     3266      1       2   \n",
       "4  2703,886,1253,1261,2365,3087,941,305,3061,711,...     3266      1       5   \n",
       "\n",
       "   click_timestamp  hist_len  gender  age  item_date  \\\n",
       "0        974711543        50       1    4         29   \n",
       "1                0        50       1    4         29   \n",
       "2        968098376        50       2    6         29   \n",
       "3        976210413        50       1    3         29   \n",
       "4       1023534057        50       2    1         29   \n",
       "\n",
       "                            item_title  item_cate_id  \n",
       "0  4566,4567,0,0,0,0,0,0,0,0,0,0,0,0,0             6  \n",
       "1  4566,4567,0,0,0,0,0,0,0,0,0,0,0,0,0             6  \n",
       "2  4566,4567,0,0,0,0,0,0,0,0,0,0,0,0,0             6  \n",
       "3  4566,4567,0,0,0,0,0,0,0,0,0,0,0,0,0             6  \n",
       "4  4566,4567,0,0,0,0,0,0,0,0,0,0,0,0,0             6  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_csv('../data/ml-1m/train_df.csv')\n",
    "test_df = pd.read_csv('../data/ml-1m/test_df.csv')\n",
    "data = train_df.append(test_df)\n",
    "print('train_df.shape: {}, test_df.shape: {}'.format(train_df.shape, test_df.shape))\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c67cb958",
   "metadata": {},
   "source": [
    "##### 数据预处理\n",
    "\n",
    "行为序列padding\n",
    "\n",
    "    pad_sequences([[1,2,3], [2, 3]], maxlen=5, value=0) =》\n",
    "    array([[0, 0, 1, 2, 3],\n",
    "           [0, 0, 0, 2, 3]], dtype=int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4d56bf7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\SoftwareInstall\\Anaconda\\envs\\py36\\lib\\site-packages\\ipykernel_launcher.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "# 当前item作为序列最后一个item\n",
    "data['hist_item_id'] = data['hist_item_id'] + ',' + data['item_id'].map(str)\n",
    "\n",
    "def parse_seqs_padding(seqs, maxlen=50):\n",
    "    \"\"\" 左补零填充 \"\"\"\n",
    "    x = [i for i in seqs.split(',') if i != '0'][-maxlen:]\n",
    "    return ','.join(['0']*(maxlen-len(x)) + x)\n",
    "\n",
    "data['hist_item_id'] = data['hist_item_id'].apply(parse_seqs_padding, args=(20,))\n",
    "\n",
    "# dense feture标准化\n",
    "dense_column_names, sparse_column_names, varlen_sparse_column_names = ['hist_len'], [], ['hist_item_id']\n",
    "\n",
    "def data_processing(df, dense_column_names,\n",
    "                    sparse_column_names,\n",
    "                    varlen_sparse_column_names):\n",
    "    df[dense_column_names] = df[dense_column_names].fillna(0.0)\n",
    "    for f in dense_column_names:\n",
    "        df[f] = df[f].apply(lambda x: np.log(x+1) if x > -1 else -1)\n",
    "    \n",
    "    df[sparse_column_names] = df[sparse_column_names].fillna(\"-1\")\n",
    "    for f in sparse_column_names:\n",
    "        lbe = LabelEncoder()\n",
    "        df[f] = lbe.fit_transform(df[f])\n",
    "    return df[dense_column_names + sparse_column_names + varlen_sparse_column_names]\n",
    "\n",
    "df = data_processing(data, dense_column_names, sparse_column_names, varlen_sparse_column_names)\n",
    "df['label'] = data['label']\n",
    "\n",
    "train_df, test_df = df.iloc[0:train_df.shape[0]], df.iloc[train_df.shape[0]:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f426d16",
   "metadata": {},
   "source": [
    "##### 模型构建\n",
    "\n",
    "Dense特征和序列特征输入LSTM模型中学习。\n",
    "\n",
    "SpatialDropout1D 随机的对部分区域置0(Dropout随机的对部分元素置0)，输入为(samples, timesteps, channels)或(samples, sequence_length, embedding_dim)。\n",
    "\n",
    "LSTM(units,input_shape(3,1)), units指cell中隐藏神经元个数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5472cbdd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[DenseFeature(name='hist_len', dimension=1),\n",
       " VarLenSparseFeature(name='hist_item_id', vocabulary_size=3884, embedding_size=4, maxlen=20)]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SparseFeature = namedtuple('SparseFeature', ['name', 'vocabulary_size', 'embedding_size'])\n",
    "DenseFeature = namedtuple('DenseFeature', ['name', 'dimension'])\n",
    "VarLenSparseFeature = namedtuple('VarLenSparseFeature', ['name', 'vocabulary_size', 'embedding_size', 'maxlen'])\n",
    "\n",
    "feature_columns = [\n",
    "#     SparseFeature('user_id', data.user_id.max()+1, embedding_size=4),\n",
    "#     SparseFeature('gender', data.gender.max()+1, embedding_size=4),\n",
    "#     SparseFeature('age', data.age.max()+1, embedding_size=4),\n",
    "#     SparseFeature('item_id', data.item_id.max()+1, embedding_size=4),\n",
    "#     SparseFeature('item_cate_id', data.item_cate_id.max()+1, embedding_size=4),\n",
    "    DenseFeature('hist_len', 1),\n",
    "    VarLenSparseFeature('hist_item_id', data.item_id.max()+1, embedding_size=4, maxlen=20)\n",
    "]\n",
    "\n",
    "feature_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "db186681",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lstm.shape:  (None, 20, 200)\n",
      "time_dist.shape:  (None, 20, 4)\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "hist_item_id (InputLayer)       [(None, 20)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "var_emb_hist_item_id (Embedding (None, 20, 4)        15540       hist_item_id[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d (SpatialDropo (None, 20, 4)        0           var_emb_hist_item_id[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     (None, 20, 200)      164000      spatial_dropout1d[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed (TimeDistribut (None, 20, 4)        804         lstm[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "pooling (Pooling)               (None, 4)            0           time_distributed[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "pooling_1 (Pooling)             (None, 4)            0           time_distributed[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 8)            0           pooling[0][0]                    \n",
      "                                                                 pooling_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 3)            27          concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 3)            12          dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 3)            0           batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 3)            0           activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "hist_len (InputLayer)           [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 1)            4           dropout[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 180,387\n",
      "Trainable params: 180,381\n",
      "Non-trainable params: 6\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def model_metric(prob, label, thr=0.5):\n",
    "    \"\"\" 模型评估 \"\"\"\n",
    "    # AUC\n",
    "    fpr, tpr, threshold = metrics.roc_curve(label, prob)\n",
    "    auc = metrics.auc(fpr, tpr)\n",
    "    score = metrics.accuracy_score(label, prob > thr)\n",
    "    # LogLoss\n",
    "    logloss = log_loss(label, prob)\n",
    "    print('模型准确率:{}, AUC得分:{}, LogLoss:{}'.format(score, auc, logloss))\n",
    "    print(classification_report(label, prob > thr, digits=2))\n",
    "    print('==========================================================')\n",
    "\n",
    "class Pooling(Layer):\n",
    "    def __init__(self, pooling_type='max'):\n",
    "        super(Pooling, self).__init__()\n",
    "        self.pooling_type = pooling_type\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        _input = inputs\n",
    "        if self.pooling_type=='max':\n",
    "            output = tf.reduce_max(_input, 1, keepdims=False)\n",
    "        elif self.pooling_type=='mean':\n",
    "            output = tf.reduce_mean(_input, 1, keepdims=False)\n",
    "        else:\n",
    "            raise Exception(\"pooling_type error\")\n",
    "        return output\n",
    "    \n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return (None, 1)\n",
    "    \n",
    "def build_input_layers(feature_columns):\n",
    "    \"\"\" 构建输入层 \"\"\"\n",
    "    dense_input_dict, sparse_input_dict, varlen_sparse_input_dict = {}, {}, {}\n",
    "    for f in feature_columns:\n",
    "        if isinstance(f, DenseFeature):\n",
    "            dense_input_dict[f.name] = Input(shape=(f.dimension, ), name=f.name)\n",
    "        elif isinstance(f, SparseFeature):\n",
    "            sparse_input_dict[f.name] = Input(shape=(1, ), name=f.name)\n",
    "        elif isinstance(f, VarLenSparseFeature):\n",
    "            varlen_sparse_input_dict[f.name] = Input(shape=(f.maxlen, ), name=f.name)\n",
    "    return dense_input_dict, sparse_input_dict, varlen_sparse_input_dict\n",
    "    \n",
    "def build_embedding_layers(feature_columns, is_linear):\n",
    "    \"\"\" 构建embedding层 \"\"\"\n",
    "    embedding_layer_dict = {}\n",
    "    sparse_feature_columns = list(filter(lambda x: isinstance(x, SparseFeature), feature_columns))\n",
    "    varlen_sparse_feature_columns = list(filter(lambda x: isinstance(x, VarLenSparseFeature), feature_columns))\n",
    "    if is_linear:\n",
    "        # 序列特征不参与线性模型的运算\n",
    "        for f in sparse_feature_columns:\n",
    "            embedding_layer_dict[f.name] = Embedding(f.vocabulary_size+1, 1, name='1d_emb_' + f.name)\n",
    "    else:\n",
    "        for f in sparse_feature_columns:\n",
    "            embedding_layer_dict[f.name] = Embedding(f.vocabulary_size+1, f.embedding_size, name='kd_emb_' + f.name)\n",
    "        for f in varlen_sparse_feature_columns:\n",
    "            embedding_layer_dict[f.name] = Embedding(f.vocabulary_size+1, f.embedding_size, name='var_emb_' + f.name, mask_zero=True)\n",
    "    return embedding_layer_dict\n",
    "\n",
    "def LSTMRec(feature_columns, behavior_seq_column_names):\n",
    "    dense_input_dict, sparse_input_dict, varlen_sparse_input_dict = build_input_layers(feature_columns)\n",
    "    input_list = list(dense_input_dict.values()) + list(sparse_input_dict.values()) + list(varlen_sparse_input_dict.values())\n",
    "    kd_embedding_layer_dict = build_embedding_layers(feature_columns, is_linear=False)\n",
    "    \n",
    "    lstm_pooling_list = []\n",
    "    for i in range(len(behavior_seq_column_names)):\n",
    "        seq_embed = kd_embedding_layer_dict[behavior_seq_column_names[i]](varlen_sparse_input_dict[behavior_seq_column_names[i]])\n",
    "        _dropout = SpatialDropout1D(rate=0.2)\n",
    "        dropout_seq_embed = _dropout(seq_embed) # (None, 50, 4)    \n",
    "        #print('dropout_seq_embed.shape: ', dropout_seq_embed.shape) \n",
    "        _lstm = LSTM(200, return_sequences=True, dropout=0.2)(dropout_seq_embed) # (None, 50, 200)\n",
    "        # 相当于对每一个时间步增加一个dense，改变最后一个维度。\n",
    "        _time_dist = TimeDistributed(Dense(4, activation='tanh'))(_lstm) # (None, 50, 4)\n",
    "        print('lstm.shape: ', _lstm.shape)\n",
    "        print('time_dist.shape: ', _time_dist.shape)\n",
    "        \n",
    "        # 对最后一个维度做max和mean\n",
    "        max_pooling = Pooling(pooling_type='max')(_time_dist) # (None, 4)\n",
    "        mean_pooling = Pooling(pooling_type='mean')(_time_dist) # (None, 4)\n",
    "        lstm_pooling_list.append(max_pooling)\n",
    "        lstm_pooling_list.append(mean_pooling)\n",
    "\n",
    "    # 拼接dense特征\n",
    "    concat_dense_inputs = Concatenate(axis=1)(list(dense_input_dict.values())) # (None, 8)\n",
    "    dense_output = Dense(3)(concat_dense_inputs)\n",
    "    \n",
    "    concat_lstm_dense = Concatenate(axis=1)(lstm_pooling_list)#Concatenate(axis=1)(lstm_pooling_list + [dense_output])\n",
    "    x = Dropout(0.2)(Activation(activation='relu')(BatchNormalization()(Dense(3)(concat_lstm_dense))))\n",
    "    output_layer = Dense(1, activation='sigmoid')(x)\n",
    "    model = Model(inputs=input_list, outputs=output_layer)\n",
    "    return model\n",
    "\n",
    "behavior_seq_column_names = ['hist_item_id']\n",
    "model = LSTMRec(feature_columns, behavior_seq_column_names)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0d125786",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1529/1529 [==============================] - 1060s 685ms/step - loss: 0.5461 - binary_crossentropy: 0.5461 - auc: 0.7890 - val_loss: 0.7789 - val_binary_crossentropy: 0.7789 - val_auc: 0.5662\n",
      "Epoch 2/100\n",
      "1529/1529 [==============================] - 768s 502ms/step - loss: 0.5118 - binary_crossentropy: 0.5118 - auc: 0.8186 - val_loss: 0.6730 - val_binary_crossentropy: 0.6730 - val_auc: 0.6166\n",
      "Epoch 3/100\n",
      "1529/1529 [==============================] - 760s 497ms/step - loss: 0.5052 - binary_crossentropy: 0.5052 - auc: 0.8236 - val_loss: 0.8210 - val_binary_crossentropy: 0.8210 - val_auc: 0.6200\n",
      "Epoch 4/100\n",
      "1529/1529 [==============================] - 758s 496ms/step - loss: 0.5003 - binary_crossentropy: 0.5003 - auc: 0.8274 - val_loss: 0.7616 - val_binary_crossentropy: 0.7616 - val_auc: 0.6343\n",
      "Epoch 5/100\n",
      "1529/1529 [==============================] - 757s 495ms/step - loss: 0.4848 - binary_crossentropy: 0.4848 - auc: 0.8412 - val_loss: 0.6058 - val_binary_crossentropy: 0.6058 - val_auc: 0.6832\n",
      "Epoch 6/100\n",
      "1529/1529 [==============================] - 748s 489ms/step - loss: 0.4687 - binary_crossentropy: 0.4687 - auc: 0.8535 - val_loss: 0.6147 - val_binary_crossentropy: 0.6147 - val_auc: 0.7264\n",
      "Epoch 7/100\n",
      "1529/1529 [==============================] - 645s 422ms/step - loss: 0.4611 - binary_crossentropy: 0.4611 - auc: 0.8585 - val_loss: 0.5761 - val_binary_crossentropy: 0.5761 - val_auc: 0.7413\n",
      "Epoch 8/100\n",
      "1529/1529 [==============================] - 413s 270ms/step - loss: 0.4569 - binary_crossentropy: 0.4569 - auc: 0.8612 - val_loss: 0.6704 - val_binary_crossentropy: 0.6704 - val_auc: 0.7555\n",
      "Epoch 9/100\n",
      "1529/1529 [==============================] - 422s 276ms/step - loss: 0.4526 - binary_crossentropy: 0.4526 - auc: 0.8640 - val_loss: 0.6965 - val_binary_crossentropy: 0.6965 - val_auc: 0.7656\n",
      "Epoch 10/100\n",
      "1529/1529 [==============================] - 412s 270ms/step - loss: 0.4488 - binary_crossentropy: 0.4488 - auc: 0.8665 - val_loss: 0.6029 - val_binary_crossentropy: 0.6029 - val_auc: 0.7714\n",
      "Epoch 11/100\n",
      "1529/1529 [==============================] - 411s 269ms/step - loss: 0.4442 - binary_crossentropy: 0.4442 - auc: 0.8695 - val_loss: 0.6910 - val_binary_crossentropy: 0.6910 - val_auc: 0.7850\n",
      "Epoch 12/100\n",
      "1529/1529 [==============================] - 408s 267ms/step - loss: 0.4404 - binary_crossentropy: 0.4404 - auc: 0.8719 - val_loss: 0.6183 - val_binary_crossentropy: 0.6183 - val_auc: 0.7794\n",
      "Epoch 13/100\n",
      "1529/1529 [==============================] - 411s 269ms/step - loss: 0.4367 - binary_crossentropy: 0.4367 - auc: 0.8742 - val_loss: 0.6243 - val_binary_crossentropy: 0.6243 - val_auc: 0.7780\n",
      "Epoch 14/100\n",
      "1529/1529 [==============================] - 409s 268ms/step - loss: 0.4338 - binary_crossentropy: 0.4338 - auc: 0.8762 - val_loss: 0.6425 - val_binary_crossentropy: 0.6425 - val_auc: 0.7950\n",
      "Epoch 15/100\n",
      "1529/1529 [==============================] - 411s 269ms/step - loss: 0.4319 - binary_crossentropy: 0.4319 - auc: 0.8774 - val_loss: 0.6324 - val_binary_crossentropy: 0.6324 - val_auc: 0.7950\n",
      "Epoch 16/100\n",
      "1529/1529 [==============================] - 417s 273ms/step - loss: 0.4296 - binary_crossentropy: 0.4296 - auc: 0.8788 - val_loss: 0.6534 - val_binary_crossentropy: 0.6534 - val_auc: 0.7970\n",
      "Epoch 17/100\n",
      "1529/1529 [==============================] - 411s 269ms/step - loss: 0.4273 - binary_crossentropy: 0.4273 - auc: 0.8804 - val_loss: 0.6614 - val_binary_crossentropy: 0.6614 - val_auc: 0.8058\n",
      "Epoch 00017: early stopping\n",
      "Wall time: 2h 41min 20s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2029fc4deb8>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "train_input = {\n",
    "#     'user_id': np.array(train['user_id']),\n",
    "#     'gender': np.array(train['gender']),\n",
    "#     'age': np.array(train['age']),\n",
    "#     'item_id': np.array(train['item_id']),\n",
    "#     'item_cate_id': np.array(train['item_cate_id']),\n",
    "    'hist_item_id': np.array([[int(i) for i in s.split(',')] for s in train_df['hist_item_id']]),\n",
    "    'hist_len': np.array(train_df['hist_len']),\n",
    "}\n",
    "test_input = {\n",
    "#     'user_id': np.array(test['user_id']),\n",
    "#     'gender': np.array(test['gender']),\n",
    "#     'age': np.array(test['age']),\n",
    "#     'item_id': np.array(test['item_id']),\n",
    "#     'item_cate_id': np.array(test['item_cate_id']),\n",
    "    'hist_item_id': np.array([[int(i) for i in s.split(',')] for s in test_df['hist_item_id']]),\n",
    "    'hist_len': np.array(test_df['hist_len']),\n",
    "}\n",
    "\n",
    "# 模型训练\n",
    "my_callbacks = [\n",
    "    EarlyStopping(monitor='val_loss', patience=10, verbose=2, mode='auto')\n",
    "]\n",
    "model.compile('adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=[\"binary_crossentropy\", tf.keras.metrics.AUC(name='auc')])\n",
    "model.fit(train_input,\n",
    "          train_df['label'].values,\n",
    "          batch_size=1024,\n",
    "          epochs=100,\n",
    "          validation_split=0.2,\n",
    "          callbacks=my_callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "00a804e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "模型准确率:0.7630402384500745, AUC得分:0.8479906371128547, LogLoss:0.5091028924468036\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.66      0.73      6038\n",
      "           1       0.72      0.87      0.79      6040\n",
      "\n",
      "    accuracy                           0.76     12078\n",
      "   macro avg       0.78      0.76      0.76     12078\n",
      "weighted avg       0.78      0.76      0.76     12078\n",
      "\n",
      "==========================================================\n"
     ]
    }
   ],
   "source": [
    "# 模型预测与评估\n",
    "result = model.predict(test_input)\n",
    "model_metric(np.array([i[0] for i in result]), test_df['label'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "628593a0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
