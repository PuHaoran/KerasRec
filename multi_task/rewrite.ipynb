{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c37ed43d",
   "metadata": {},
   "source": [
    "## Rewrite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6cacd1f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import namedtuple\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.models import *\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.python.keras.callbacks import EarlyStopping\n",
    "from sklearn.preprocessing import  MinMaxScaler, LabelEncoder\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.metrics import classification_report, roc_curve"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb15db7c",
   "metadata": {},
   "source": [
    "##### 获取数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "feed2de5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "各行为比例:  0.03501586934580252 0.02580487086290815 0.007533327266004016 0.0038211876059220415\n",
      "train_df.shape: (6708846, 13), test_df.shape: (609036, 13)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>videoplayseconds</th>\n",
       "      <th>userid</th>\n",
       "      <th>feedid</th>\n",
       "      <th>authorid</th>\n",
       "      <th>bgm_song_id</th>\n",
       "      <th>bgm_singer_id</th>\n",
       "      <th>manual_keyword_list</th>\n",
       "      <th>manual_tag_list</th>\n",
       "      <th>read_comment</th>\n",
       "      <th>like</th>\n",
       "      <th>click_avatar</th>\n",
       "      <th>forward</th>\n",
       "      <th>sample_weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5143704</th>\n",
       "      <td>1.946289</td>\n",
       "      <td>5832</td>\n",
       "      <td>6529</td>\n",
       "      <td>263</td>\n",
       "      <td>2935</td>\n",
       "      <td>2451</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[4, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5793422</th>\n",
       "      <td>4.078125</td>\n",
       "      <td>10483</td>\n",
       "      <td>408</td>\n",
       "      <td>276</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[5, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3867148</th>\n",
       "      <td>4.109375</td>\n",
       "      <td>1117</td>\n",
       "      <td>1954</td>\n",
       "      <td>857</td>\n",
       "      <td>784</td>\n",
       "      <td>781</td>\n",
       "      <td>[276, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0...</td>\n",
       "      <td>[88, 55, 9, 48, 2, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3133071</th>\n",
       "      <td>3.712891</td>\n",
       "      <td>13508</td>\n",
       "      <td>54</td>\n",
       "      <td>270</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[62, 241, 1220, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[34, 35, 9, 2, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4400240</th>\n",
       "      <td>3.611328</td>\n",
       "      <td>4425</td>\n",
       "      <td>2309</td>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[276, 1702, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0...</td>\n",
       "      <td>[88, 55, 9, 48, 2, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         videoplayseconds  userid  feedid  authorid  bgm_song_id  \\\n",
       "5143704          1.946289    5832    6529       263         2935   \n",
       "5793422          4.078125   10483     408       276            1   \n",
       "3867148          4.109375    1117    1954       857          784   \n",
       "3133071          3.712891   13508      54       270            1   \n",
       "4400240          3.611328    4425    2309        26            1   \n",
       "\n",
       "         bgm_singer_id                                manual_keyword_list  \\\n",
       "5143704           2451  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "5793422              1  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "3867148            781  [276, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0...   \n",
       "3133071              1  [62, 241, 1220, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "4400240              1  [276, 1702, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0...   \n",
       "\n",
       "                              manual_tag_list  read_comment  like  \\\n",
       "5143704     [4, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0]             0     0   \n",
       "5793422     [5, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0]             0     0   \n",
       "3867148  [88, 55, 9, 48, 2, 0, 0, 0, 0, 0, 0]             0     0   \n",
       "3133071   [34, 35, 9, 2, 0, 0, 0, 0, 0, 0, 0]             1     0   \n",
       "4400240  [88, 55, 9, 48, 2, 0, 0, 0, 0, 0, 0]             0     0   \n",
       "\n",
       "         click_avatar  forward  sample_weight  \n",
       "5143704             0        0            0.0  \n",
       "5793422             0        0            0.0  \n",
       "3867148             0        0            0.0  \n",
       "3133071             0        0            1.0  \n",
       "4400240             0        0            0.0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_wechat_data():\n",
    "    \"\"\" 读取wechat数据集 \"\"\"\n",
    "    train_path = '../data/wechat/train_df.pkl'\n",
    "    test_path = '../data/wechat/test_df.pkl'\n",
    "    encoder_dict_path = '../data/wechat/encoder_dict.pkl'\n",
    "    train_df = pd.read_pickle(train_path)\n",
    "    test_df = pd.read_pickle(test_path)\n",
    "    encoder_dict = joblib.load(encoder_dict_path)\n",
    "    return train_df, test_df, encoder_dict\n",
    "\n",
    "train_df, test_df, encoder_dict = get_wechat_data()\n",
    "train_df = train_df.sample(frac=1.0)\n",
    "\n",
    "# 按行为比例加权\n",
    "data = pd.concat([train_df, test_df], axis=0)\n",
    "print('各行为比例: ', data.read_comment.sum() / data.shape[0], data.like.sum() / data.shape[0], data.click_avatar.sum() / data.shape[0], data.forward.sum() / data.shape[0])\n",
    "data['sample_weight'] = data['read_comment']*1.0+data['like']*1.1+data['click_avatar']*1.2+data['forward']*2.0\n",
    "\n",
    "train_df, test_df = data.iloc[:train_df.shape[0]], data.iloc[train_df.shape[0]:]\n",
    "print('train_df.shape: {}, test_df.shape: {}'.format(train_df.shape, test_df.shape))\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d07151e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SparseFeature(name='userid', vocabulary_size=17390, embedding_size=4),\n",
       " SparseFeature(name='feedid', vocabulary_size=16448, embedding_size=4),\n",
       " SparseFeature(name='authorid', vocabulary_size=6966, embedding_size=4),\n",
       " SparseFeature(name='bgm_song_id', vocabulary_size=5773, embedding_size=4),\n",
       " SparseFeature(name='bgm_singer_id', vocabulary_size=4573, embedding_size=4),\n",
       " DenseFeature(name='videoplayseconds', dimension=1),\n",
       " VarLenSparseFeature(name='manual_keyword_list', vocabulary_size=21576, embedding_size=4, maxlen=18),\n",
       " VarLenSparseFeature(name='manual_tag_list', vocabulary_size=349, embedding_size=4, maxlen=11)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target = ['read_comment', 'like', 'click_avatar', 'forward']\n",
    "\n",
    "# 稠密特征、稀疏特征、变长稀疏特征\n",
    "dense_column_names = ['videoplayseconds']\n",
    "sparse_column_names = ['userid', 'feedid', 'authorid', 'bgm_song_id', 'bgm_singer_id']\n",
    "varlen_sparse_column_names = ['manual_keyword_list', 'manual_tag_list']\n",
    "\n",
    "SparseFeature = namedtuple('SparseFeature', ['name', 'vocabulary_size', 'embedding_size'])\n",
    "DenseFeature = namedtuple('DenseFeature', ['name', 'dimension'])\n",
    "VarLenSparseFeature = namedtuple('VarLenSparseFeature', ['name', 'vocabulary_size', 'embedding_size', 'maxlen'])\n",
    "\n",
    "varlen_sparse_column_maxlen_dict = {\n",
    "    'manual_keyword_list': 18,\n",
    "    'manual_tag_list': 11\n",
    "}\n",
    "\n",
    "feature_columns = [SparseFeature(f, vocabulary_size=data[f].nunique(), embedding_size=4) for f in sparse_column_names] + \\\n",
    "[DenseFeature(f, 1) for f in dense_column_names] + \\\n",
    "[VarLenSparseFeature(f, len(encoder_dict[f])+1, embedding_size=4, maxlen=varlen_sparse_column_maxlen_dict[f]) for f in varlen_sparse_column_names]\n",
    "feature_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "11d995c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "concat_embed.shape:  (None, 28)\n",
      "Model: \"reweight_model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "manual_keyword_list (InputLayer [(None, 18)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "manual_tag_list (InputLayer)    [(None, 11)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "userid (InputLayer)             [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "feedid (InputLayer)             [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "authorid (InputLayer)           [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "bgm_song_id (InputLayer)        [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "bgm_singer_id (InputLayer)      [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "var_emb_manual_keyword_list (Em (None, 18, 4)        86308       manual_keyword_list[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "var_emb_manual_tag_list (Embedd (None, 11, 4)        1400        manual_tag_list[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "kd_emb_userid (Embedding)       (None, 1, 4)         69564       userid[0][0]                     \n",
      "                                                                 userid[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "kd_emb_feedid (Embedding)       (None, 1, 4)         65796       feedid[0][0]                     \n",
      "                                                                 feedid[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "kd_emb_authorid (Embedding)     (None, 1, 4)         27868       authorid[0][0]                   \n",
      "                                                                 authorid[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "kd_emb_bgm_song_id (Embedding)  (None, 1, 4)         23096       bgm_song_id[0][0]                \n",
      "                                                                 bgm_song_id[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "kd_emb_bgm_singer_id (Embedding (None, 1, 4)         18296       bgm_singer_id[0][0]              \n",
      "                                                                 bgm_singer_id[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "masking_2 (Masking)             (None, 18, 4)        0           var_emb_manual_keyword_list[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "masking_3 (Masking)             (None, 11, 4)        0           var_emb_manual_tag_list[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "flatten_15 (Flatten)            (None, 4)            0           kd_emb_userid[1][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_16 (Flatten)            (None, 4)            0           kd_emb_feedid[1][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_17 (Flatten)            (None, 4)            0           kd_emb_authorid[1][0]            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_18 (Flatten)            (None, 4)            0           kd_emb_bgm_song_id[1][0]         \n",
      "__________________________________________________________________________________________________\n",
      "flatten_19 (Flatten)            (None, 4)            0           kd_emb_bgm_singer_id[1][0]       \n",
      "__________________________________________________________________________________________________\n",
      "mean_pooling_layer_2 (MeanPooli (None, 4)            0           masking_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "mean_pooling_layer_3 (MeanPooli (None, 4)            0           masking_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 28)           0           flatten_15[0][0]                 \n",
      "                                                                 flatten_16[0][0]                 \n",
      "                                                                 flatten_17[0][0]                 \n",
      "                                                                 flatten_18[0][0]                 \n",
      "                                                                 flatten_19[0][0]                 \n",
      "                                                                 mean_pooling_layer_2[0][0]       \n",
      "                                                                 mean_pooling_layer_3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 4)            116         concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "videoplayseconds (InputLayer)   [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "1d_emb_userid (Embedding)       (None, 1, 1)         17391       userid[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "1d_emb_feedid (Embedding)       (None, 1, 1)         16449       feedid[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "1d_emb_authorid (Embedding)     (None, 1, 1)         6967        authorid[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "1d_emb_bgm_song_id (Embedding)  (None, 1, 1)         5774        bgm_song_id[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "1d_emb_bgm_singer_id (Embedding (None, 1, 1)         4574        bgm_singer_id[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 4)            16          dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 1)            0           videoplayseconds[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_10 (Flatten)            (None, 1)            0           1d_emb_userid[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_11 (Flatten)            (None, 1)            0           1d_emb_feedid[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_12 (Flatten)            (None, 1)            0           1d_emb_authorid[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_13 (Flatten)            (None, 1)            0           1d_emb_bgm_song_id[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "flatten_14 (Flatten)            (None, 1)            0           1d_emb_bgm_singer_id[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 4)            0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 1)            2           concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 1)            0           flatten_10[0][0]                 \n",
      "                                                                 flatten_11[0][0]                 \n",
      "                                                                 flatten_12[0][0]                 \n",
      "                                                                 flatten_13[0][0]                 \n",
      "                                                                 flatten_14[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 5, 4)         0           kd_emb_userid[0][0]              \n",
      "                                                                 kd_emb_feedid[0][0]              \n",
      "                                                                 kd_emb_authorid[0][0]            \n",
      "                                                                 kd_emb_bgm_song_id[0][0]         \n",
      "                                                                 kd_emb_bgm_singer_id[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 4)            0           activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 1)            0           dense_3[0][0]                    \n",
      "                                                                 add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "fm__layer_1 (FM_Layer)          (None, 1)            0           concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 1)            5           dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 1)            0           add_4[0][0]                      \n",
      "                                                                 fm__layer_1[0][0]                \n",
      "                                                                 dense_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 1)            0           add_5[0][0]                      \n",
      "==================================================================================================\n",
      "Total params: 343,622\n",
      "Trainable params: 343,614\n",
      "Non-trainable params: 8\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "class FM_Layer(Layer):\n",
    "    def __init__(self):\n",
    "        super(FM_Layer, self).__init__()\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        concat_embed_values = inputs\n",
    "        #print('concat_embed_values.shape: ', concat_embed_values.shape) # (None, 26, 4)\n",
    "        sum_square = tf.square(tf.reduce_sum(concat_embed_values, axis=1, keepdims=True)) # (None, 1, 4)\n",
    "        #print('sum_square.shape: ', sum_square.shape)\n",
    "        square_sum = tf.reduce_sum(concat_embed_values * concat_embed_values, axis=1, keepdims=True) # (None, 1, 4)\n",
    "        #print('square_sum.shape: ', square_sum.shape)\n",
    "        output = sum_square - square_sum # 和的平方-平方的和\n",
    "        output = 0.5 * tf.reduce_sum(output, axis=2, keepdims=False) # (None 1)\n",
    "        #print('output.shape: ', output.shape)\n",
    "        return output\n",
    "    \n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return (None, 1)\n",
    "    \n",
    "def model_metric(prob, label, thr=0.5):\n",
    "    \"\"\" 模型评估 \"\"\"\n",
    "    # AUC\n",
    "    fpr, tpr, threshold = metrics.roc_curve(label, prob)\n",
    "    auc = metrics.auc(fpr, tpr)\n",
    "    score = metrics.accuracy_score(label, prob > thr)\n",
    "    # LogLoss\n",
    "    logloss = log_loss(label, prob)\n",
    "    print('模型准确率:{}, AUC得分:{}, LogLoss:{}'.format(score, auc, logloss))\n",
    "    print(classification_report(label, prob > thr, digits=2))\n",
    "    print('==========================================================')\n",
    "\n",
    "def build_input_layers(feature_columns):\n",
    "    \"\"\" 构建输入层 \"\"\"\n",
    "    dense_input_dict, sparse_input_dict, varlen_sparse_input_dict = {}, {}, {}\n",
    "    for f in feature_columns:\n",
    "        if isinstance(f, DenseFeature):\n",
    "            dense_input_dict[f.name] = Input(shape=(f.dimension, ), name=f.name)\n",
    "        elif isinstance(f, SparseFeature):\n",
    "            sparse_input_dict[f.name] = Input(shape=(1, ), name=f.name)\n",
    "        elif isinstance(f, VarLenSparseFeature):\n",
    "            varlen_sparse_input_dict[f.name] = Input(shape=(f.maxlen, ), name=f.name)\n",
    "    return dense_input_dict, sparse_input_dict, varlen_sparse_input_dict\n",
    "    \n",
    "def build_embedding_layers(feature_columns, is_linear):\n",
    "    \"\"\" 构建embedding层 \"\"\"\n",
    "    embedding_layer_dict = {}\n",
    "    if is_linear:\n",
    "        sparse_feature_columns = list(filter(lambda x: isinstance(x, SparseFeature), feature_columns))\n",
    "        for f in sparse_feature_columns:\n",
    "            embedding_layer_dict[f.name] = Embedding(f.vocabulary_size+1, 1, name='1d_emb_' + f.name)\n",
    "    else:\n",
    "        for f in feature_columns:\n",
    "            if isinstance(f, SparseFeature):\n",
    "                embedding_layer_dict[f.name] = Embedding(f.vocabulary_size+1, f.embedding_size, name='kd_emb_' + f.name)\n",
    "            elif isinstance(f, VarLenSparseFeature):\n",
    "                embedding_layer_dict[f.name] = Embedding(f.vocabulary_size+1, f.embedding_size, name='var_emb_' + f.name, mask_zero=True)\n",
    "    return embedding_layer_dict\n",
    "    \n",
    "def get_linear_logits(dense_input_dict, sparse_input_dict, feature_columns):\n",
    "    \"\"\" 数值特征拼接一起传入全连接层 + 类别特征onehot，flatten，add \"\"\"\n",
    "    concat_dense_inputs = Concatenate(axis=1)(list(dense_input_dict.values()))\n",
    "    dense_logits_output = Dense(1)(concat_dense_inputs)\n",
    "    \n",
    "    # embedding(input)查表操作，返回对应input的嵌入向量\n",
    "    sparse_1d_embed_list = []\n",
    "    sparse_embedding_layer_dict = build_embedding_layers(feature_columns, is_linear=True)\n",
    "    sparse_feature_columns = list(filter(lambda x: isinstance(x, SparseFeature), feature_columns))\n",
    "    for f in sparse_feature_columns:\n",
    "        _input = sparse_input_dict[f.name]\n",
    "        _embed = Flatten()(sparse_embedding_layer_dict[f.name](_input))\n",
    "        sparse_1d_embed_list.append(_embed)\n",
    "    \n",
    "    sparse_logits_output = Add()(sparse_1d_embed_list)\n",
    "    linear_logits = Add()([dense_logits_output, sparse_logits_output])\n",
    "    return linear_logits\n",
    "    \n",
    "def get_fm_logits(sparse_input_dict, embedding_layer_dict, feature_columns):\n",
    "    \"\"\" 取出input所对应的嵌入向量拼接在一起，计算和的平和-平方的和 \"\"\"\n",
    "    sparse_feature_columns = list(filter(lambda x: isinstance(x, SparseFeature), feature_columns))\n",
    "    sparse_kd_embed_list = []\n",
    "    for f in sparse_feature_columns:\n",
    "        _input = sparse_input_dict[f.name]\n",
    "        _embed = embedding_layer_dict[f.name](_input)\n",
    "        sparse_kd_embed_list.append(_embed)\n",
    "    \n",
    "    concat_sparse_kd_embed_list = Concatenate(axis=1)(sparse_kd_embed_list)\n",
    "    fm_logits = FM_Layer()(concat_sparse_kd_embed_list)\n",
    "    return fm_logits\n",
    "\n",
    "class MeanPoolingLayer(Layer):\n",
    "    def __init__(self, axis, **kwargs):\n",
    "        super(MeanPoolingLayer, self).__init__(**kwargs)\n",
    "        self.axis = axis\n",
    "        self.supports_masking = True\n",
    "    \n",
    "    def compute_mask(self, input, input_mask=None):\n",
    "        # need not to pass the mask to next layers\n",
    "        return None\n",
    "    \n",
    "    def call(self, x, mask=None):\n",
    "        if x is not None:\n",
    "            mask = K.cast(mask, K.floatx()) # (None, 18)\n",
    "            mask = K.repeat(mask, x.shape[-1]) # (None, 4, 18)\n",
    "            mask = tf.transpose(mask, [0, 2, 1]) # (None, 18, 4)\n",
    "            x = x * mask # # (None, 18, 4) * (None, 18, 4)\n",
    "            return K.sum(x, axis=self.axis) / K.sum(mask, axis=self.axis)\n",
    "        else:\n",
    "            return K.mean(x, axis=self.axis)\n",
    "\n",
    "def get_dnn_logits(sparse_input_dict, varlen_sparse_input_dict, embedding_layer_dict, feature_columns):\n",
    "    sparse_feature_columns = list(filter(lambda x: isinstance(x, SparseFeature), feature_columns))\n",
    "    varlen_sparse_feature_columns = list(filter(lambda x: isinstance(x, VarLenSparseFeature), feature_columns))\n",
    "    \n",
    "    # kd embed\n",
    "    sparse_kd_embed_list = []\n",
    "    for f in sparse_feature_columns:\n",
    "        _input = sparse_input_dict[f.name]\n",
    "        _embed = embedding_layer_dict[f.name](_input)\n",
    "        flatten_embed = Flatten()(_embed)\n",
    "        sparse_kd_embed_list.append(flatten_embed)\n",
    "    \n",
    "    # seq embed\n",
    "    varlen_sparse_embed_list = []\n",
    "    for f in varlen_sparse_feature_columns:\n",
    "        _input = varlen_sparse_input_dict[f.name] #  (None, 18)\n",
    "        _embed = embedding_layer_dict[f.name]\n",
    "        embed_layer = _embed(_input) # (None, 18, 4)\n",
    "        mask = Masking()(embed_layer) # (None, 18, 4)\n",
    "        mean_pooling_embed = MeanPoolingLayer(axis=1)(mask) # (None, 4)\n",
    "        varlen_sparse_embed_list.append(mean_pooling_embed)\n",
    "    \n",
    "    concat_embed = Concatenate(axis=1)(sparse_kd_embed_list + varlen_sparse_embed_list)\n",
    "    print('concat_embed.shape: ', concat_embed.shape)\n",
    "    \n",
    "    # DNN\n",
    "    dnn_out = Dropout(0.2)(Activation(activation='relu')(BatchNormalization()(Dense(4)(concat_embed))))\n",
    "    #dnn_out = Dropout(0.2)(Activation(activation='relu')(BatchNormalization()(Dense(4)(dnn_out))))\n",
    "    #dnn_out = Dropout(0.5)(Activation(activation='relu')(Dense(4, activation='relu')(concat_sparse_kd_embed))\n",
    "    #dnn_out = Dropout(0.5)(Dense(32, activation='relu')(dnn_out))\n",
    "    #dnn_out = Dropout(0.5)(Dense(8, activation='relu')(dnn_out))\n",
    "    dnn_logits = Dense(1)(dnn_out)\n",
    "    return dnn_logits\n",
    "    \n",
    "class ReweightModel(tf.keras.Model):\n",
    "    def train_step(self, data):\n",
    "        \"\"\" fit()传递的数据 \"\"\"\n",
    "        print('data: ', data)\n",
    "        if len(data) == 3:\n",
    "            y_prop, y_true, sample_weight = data\n",
    "        else:\n",
    "            raise \"This is a reweight model, your inputs should contain features, label, sample_weight\"\n",
    "        \n",
    "        with tf.GradientTape() as tape:\n",
    "            y_pred = self(y_prop, training=True)\n",
    "            y_true_1d = tf.cast(tf.reshape(y_true, [-1, 1]), tf.float32) # (batch, 1)\n",
    "            sample_weight_1d = tf.reshape(sample_weight, [-1, 1]) # (batch, 1)\n",
    "            \n",
    "            # compute binary_crossentropy loss\n",
    "            loss = tf.losses.binary_crossentropy(y_true_1d, y_pred, from_logits=False)[:, None]\n",
    "            # multiply sample_weight\n",
    "            loss_weight = (loss * (1 - y_true_1d) + loss * (y_true_1d) * sample_weight_1d)\n",
    "            # sum loss with weight\n",
    "            loss_sum = tf.reduce_sum(loss_weight, name=\"weight_loss_sum\")\n",
    "            # sum sample_weight\n",
    "            sample_weight_sum = tf.reduce_sum(sample_weight, name=\"sample_weight_sum\")\n",
    "            # mean batch\n",
    "            loss = tf.divide(loss_sum, sample_weight_sum, name=\"weight_logloss\")\n",
    "    \n",
    "        trainable_vars = self.trainable_variables\n",
    "        gradients = tape.gradient(loss, trainable_vars)\n",
    "\n",
    "        # update weight\n",
    "        self.optimizer.apply_gradients(zip(gradients, trainable_vars))\n",
    "\n",
    "        self.compiled_metrics.update_state(y_true, y_pred)\n",
    "\n",
    "        loss_tracker = {'logloss': loss}\n",
    "        metrics_tracker = {m.name: m.result() for m in self.metrics}\n",
    "        return {**loss_tracker, **metrics_tracker}\n",
    "    \n",
    "def DeepFM(feature_columns, seed=1024, l2_reg=1e-5, task='binary'):\n",
    "    \"\"\" Instantiates FM architecture\n",
    "    :param feature_columns \n",
    "    :param seed\n",
    "    :param l2_reg L2regularization\n",
    "    :return: A kears model instance\n",
    "    \"\"\"\n",
    "    dense_input_dict, sparse_input_dict, varlen_sparse_input_dict = build_input_layers(feature_columns)\n",
    "    input_list = list(dense_input_dict.values()) + list(sparse_input_dict.values()) + list(varlen_sparse_input_dict.values())\n",
    "    \n",
    "    # linear w * x + b\n",
    "    linear_logits = get_linear_logits(dense_input_dict, sparse_input_dict, feature_columns)\n",
    "    \n",
    "    # fm 0.5 * [sum(vixi)**2 - sum(vixi*vixi)\n",
    "    embedding_layer_dict = build_embedding_layers(feature_columns, is_linear=False)\n",
    "    fm_logits = get_fm_logits(sparse_input_dict, embedding_layer_dict, feature_columns)\n",
    "    \n",
    "    # dnn next_a = σ(w * a + b)\n",
    "    dnn_logits = get_dnn_logits(sparse_input_dict, varlen_sparse_input_dict, embedding_layer_dict, feature_columns)\n",
    "    \n",
    "    #output_logits = Add()([linear_logits])\n",
    "    #output_logits = Add()([linear_logits, fm_logits])\n",
    "    output_logits = Add()([linear_logits, fm_logits, dnn_logits])\n",
    "    output_layer = Activation(\"sigmoid\")(output_logits)\n",
    "    model = ReweightModel(input_list, output_layer)\n",
    "    return model\n",
    "\n",
    "model = DeepFM(feature_columns)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "435d6ebb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "data:  ({'videoplayseconds': <tf.Tensor 'IteratorGetNext:7' shape=(None,) dtype=float32>, 'userid': <tf.Tensor 'IteratorGetNext:6' shape=(None,) dtype=int32>, 'feedid': <tf.Tensor 'IteratorGetNext:3' shape=(None,) dtype=int32>, 'authorid': <tf.Tensor 'IteratorGetNext:0' shape=(None,) dtype=int32>, 'bgm_song_id': <tf.Tensor 'IteratorGetNext:2' shape=(None,) dtype=int32>, 'bgm_singer_id': <tf.Tensor 'IteratorGetNext:1' shape=(None,) dtype=int32>, 'manual_keyword_list': <tf.Tensor 'IteratorGetNext:4' shape=(None, 18) dtype=int32>, 'manual_tag_list': <tf.Tensor 'IteratorGetNext:5' shape=(None, 11) dtype=int32>}, (<tf.Tensor 'IteratorGetNext:8' shape=(None,) dtype=int8>,), <tf.Tensor 'IteratorGetNext:9' shape=(None,) dtype=float32>)\n",
      "data:  ({'videoplayseconds': <tf.Tensor 'IteratorGetNext:7' shape=(None,) dtype=float32>, 'userid': <tf.Tensor 'IteratorGetNext:6' shape=(None,) dtype=int32>, 'feedid': <tf.Tensor 'IteratorGetNext:3' shape=(None,) dtype=int32>, 'authorid': <tf.Tensor 'IteratorGetNext:0' shape=(None,) dtype=int32>, 'bgm_song_id': <tf.Tensor 'IteratorGetNext:2' shape=(None,) dtype=int32>, 'bgm_singer_id': <tf.Tensor 'IteratorGetNext:1' shape=(None,) dtype=int32>, 'manual_keyword_list': <tf.Tensor 'IteratorGetNext:4' shape=(None, 18) dtype=int32>, 'manual_tag_list': <tf.Tensor 'IteratorGetNext:5' shape=(None, 11) dtype=int32>}, (<tf.Tensor 'IteratorGetNext:8' shape=(None,) dtype=int8>,), <tf.Tensor 'IteratorGetNext:9' shape=(None,) dtype=float32>)\n",
      "5242/5242 [==============================] - 199s 38ms/step - logloss: 7.0954 - auc: 0.7179 - val_loss: 0.0739 - val_auc: 0.9158\n",
      "Epoch 2/100\n",
      "5242/5242 [==============================] - 36s 7ms/step - logloss: 1.3371 - auc: 0.9248 - val_loss: 0.0709 - val_auc: 0.9337\n",
      "Epoch 3/100\n",
      "5242/5242 [==============================] - 35s 7ms/step - logloss: 1.2500 - auc: 0.9390 - val_loss: 0.0691 - val_auc: 0.9352\n",
      "Epoch 4/100\n",
      "5242/5242 [==============================] - 35s 7ms/step - logloss: 1.2017 - auc: 0.9439 - val_loss: 0.0677 - val_auc: 0.9348\n",
      "Epoch 5/100\n",
      "5242/5242 [==============================] - 35s 7ms/step - logloss: 1.1809 - auc: 0.9457 - val_loss: 0.0702 - val_auc: 0.9336\n",
      "Epoch 6/100\n",
      "5242/5242 [==============================] - 36s 7ms/step - logloss: 1.1685 - auc: 0.9468 - val_loss: 0.0705 - val_auc: 0.9327\n",
      "Epoch 7/100\n",
      "5242/5242 [==============================] - 35s 7ms/step - logloss: 1.1585 - auc: 0.9478 - val_loss: 0.0730 - val_auc: 0.9312\n",
      "Epoch 8/100\n",
      "5242/5242 [==============================] - 35s 7ms/step - logloss: 1.1497 - auc: 0.9488 - val_loss: 0.0746 - val_auc: 0.9301\n",
      "Epoch 9/100\n",
      "5242/5242 [==============================] - 34s 6ms/step - logloss: 1.1406 - auc: 0.9499 - val_loss: 0.0715 - val_auc: 0.9301\n",
      "Epoch 10/100\n",
      "5242/5242 [==============================] - 34s 6ms/step - logloss: 1.1325 - auc: 0.9508 - val_loss: 0.0731 - val_auc: 0.9291\n",
      "Epoch 11/100\n",
      "5242/5242 [==============================] - 33s 6ms/step - logloss: 1.1254 - auc: 0.9516 - val_loss: 0.0716 - val_auc: 0.9288\n",
      "Epoch 12/100\n",
      "5242/5242 [==============================] - 35s 7ms/step - logloss: 1.1187 - auc: 0.9524 - val_loss: 0.0731 - val_auc: 0.9278\n",
      "Epoch 13/100\n",
      "5242/5242 [==============================] - 34s 7ms/step - logloss: 1.1120 - auc: 0.9529 - val_loss: 0.0737 - val_auc: 0.9269\n",
      "Epoch 14/100\n",
      "5242/5242 [==============================] - 34s 7ms/step - logloss: 1.1062 - auc: 0.9535 - val_loss: 0.0752 - val_auc: 0.9262\n",
      "Epoch 00014: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x15ac78e0160>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 模型训练\n",
    "train_input = {f: np.array([row for row in train_df[f]]) for f in dense_column_names + sparse_column_names + varlen_sparse_column_names}\n",
    "test_input = {f: np.array([row for row in test_df[f]]) for f in dense_column_names + sparse_column_names + varlen_sparse_column_names}\n",
    "\n",
    "my_callbacks = [\n",
    "    EarlyStopping(monitor='val_loss', patience=10, verbose=2, mode='auto')\n",
    "]\n",
    "\n",
    "loss = tf.keras.losses.binary_crossentropy\n",
    "model.compile('adam',\n",
    "              loss=loss,\n",
    "              metrics=tf.keras.metrics.AUC(name='auc'))\n",
    "\n",
    "# 单个任务\n",
    "y_list = [train_df[i].values for i in target[:1]]\n",
    "model.fit(x=train_input,\n",
    "          y=y_list,\n",
    "          sample_weight=train_df['sample_weight'].values,\n",
    "          batch_size=1024,\n",
    "          epochs=100,\n",
    "          validation_split=0.2,\n",
    "          callbacks=my_callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5d6a04ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 read_comment\n",
      "模型准确率:0.9586806034454449, AUC得分:0.9090740237023934, LogLoss:0.11337686608195455\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.98      0.98    588439\n",
      "           1       0.35      0.26      0.30     20597\n",
      "\n",
      "    accuracy                           0.96    609036\n",
      "   macro avg       0.66      0.62      0.64    609036\n",
      "weighted avg       0.95      0.96      0.96    609036\n",
      "\n",
      "==========================================================\n",
      "1 like\n",
      "模型准确率:0.9522228571053271, AUC得分:0.561270940380196, LogLoss:0.22748518754859673\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.97      0.98    594422\n",
      "           1       0.02      0.03      0.03     14614\n",
      "\n",
      "    accuracy                           0.95    609036\n",
      "   macro avg       0.50      0.50      0.50    609036\n",
      "weighted avg       0.95      0.95      0.95    609036\n",
      "\n",
      "==========================================================\n",
      "2 click_avatar\n",
      "模型准确率:0.9679756204887724, AUC得分:0.5432700738530556, LogLoss:0.11786122998572322\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.98      0.98    604496\n",
      "           1       0.01      0.03      0.01      4540\n",
      "\n",
      "    accuracy                           0.97    609036\n",
      "   macro avg       0.50      0.50      0.50    609036\n",
      "weighted avg       0.99      0.97      0.98    609036\n",
      "\n",
      "==========================================================\n",
      "3 forward\n",
      "模型准确率:0.9717110318601856, AUC得分:0.49294708635275203, LogLoss:0.09224179261203908\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.97      0.99    606975\n",
      "           1       0.00      0.02      0.00      2061\n",
      "\n",
      "    accuracy                           0.97    609036\n",
      "   macro avg       0.50      0.50      0.49    609036\n",
      "weighted avg       0.99      0.97      0.98    609036\n",
      "\n",
      "==========================================================\n"
     ]
    }
   ],
   "source": [
    "# 模型预测与评估\n",
    "result = model.predict(test_input)\n",
    "\n",
    "for idx, target_name in enumerate(target):\n",
    "    print(idx, target_name)\n",
    "    model_metric(np.array([i[0] for i in result]), test_df[target_name].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afbfe30e",
   "metadata": {},
   "source": [
    "##### 不同行为加权gAUC分数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f77db8df",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\SoftwareInstall\\Anaconda\\envs\\py36\\lib\\site-packages\\ipykernel_launcher.py:75: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "action:  read_comment\n",
      "action:  like\n",
      "action:  click_avatar\n",
      "action:  forward\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'score': 0.5509,\n",
       " 'score_detail': {'read_comment': 0.6048038200546656,\n",
       "  'like': 0.5085832840871161,\n",
       "  'click_avatar': 0.5314385168541587,\n",
       "  'forward': 0.5011312346147583}}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.stats import rankdata\n",
    "from collections import defaultdict\n",
    "\n",
    "def fast_auc(actual, predicted):\n",
    "    # https://www.kaggle.com/c/riiid-test-answer-prediction/discussion/208031    \n",
    "    pred_ranks = rankdata(predicted)\n",
    "    n_pos = np.sum(actual)\n",
    "    n_neg = len(actual) - n_pos\n",
    "    return (np.sum(pred_ranks[actual == 1]) - n_pos*(n_pos+1)/2) / (n_pos*n_neg)\n",
    "\n",
    "def uAUC(labels, preds, users):\n",
    "    \"\"\" 计算uAUC \"\"\"\n",
    "    label_dict, pred_dict, user_flag_dict = defaultdict(lambda: []), defaultdict(lambda: []), defaultdict(lambda: False)\n",
    "    for idx, label in enumerate(labels):\n",
    "        user = users[idx]\n",
    "        pred = preds[idx]\n",
    "        label = labels[idx]\n",
    "        label_dict[user].append(label)\n",
    "        pred_dict[user].append(pred)\n",
    "    \n",
    "    # 当前用户是否全为正/负样本\n",
    "    for user in set(users):\n",
    "        _labels = label_dict[user]\n",
    "        flag = False\n",
    "        for i in range(len(_labels)-1):\n",
    "            if _labels[i] != _labels[i+1]:\n",
    "                flag = True\n",
    "                break\n",
    "        user_flag_dict[user] = flag\n",
    "    \n",
    "    auc_sum = 0.0\n",
    "    auc_cnt = 0.0\n",
    "    for user in user_flag_dict:\n",
    "        if user_flag_dict[user]:\n",
    "            auc = fast_auc(np.asarray(label_dict[user]), np.asarray(pred_dict[user]))\n",
    "            auc_sum += auc\n",
    "            auc_cnt += 1.0\n",
    "    return auc_sum * 1.0 / auc_cnt\n",
    "\n",
    "def score(result_df, action_list):\n",
    "    \"\"\" 计算多个行为的加权gAUC分数 \"\"\"\n",
    "    weight_dict = {\n",
    "        \"read_comment\": 4.0,  # 是否查看评论\n",
    "        \"like\": 3.0,  # 是否点赞\n",
    "        \"click_avatar\": 2.0,  # 是否点击头像\n",
    "        \"forward\": 1.0,  # 是否转发\n",
    "        \"favorite\": 1.0,  # 是否收藏\n",
    "        \"comment\": 1.0,  # 是否发表评论\n",
    "        \"follow\": 1.0  # 是否关注\n",
    "    }\n",
    "    \n",
    "    score = 0.0\n",
    "    score_dict = {}\n",
    "    weight_sum = 0.0\n",
    "    for action in action_list:\n",
    "        print('action: ', action)\n",
    "        labels = result_df[action].values\n",
    "        preds = result_df['p'+action].values\n",
    "        users = result_df['userid'].values\n",
    "        weight = weight_dict[action]\n",
    "        gauc = uAUC(labels, preds, users)\n",
    "        score_dict[action] = gauc\n",
    "        score += weight * gauc\n",
    "        weight_sum += weight\n",
    "    \n",
    "    score /= weight_sum\n",
    "    score = round(score, 4)\n",
    "    return {\n",
    "        'score': score,\n",
    "        'score_detail': score_dict\n",
    "    } \n",
    "\n",
    "result_df = test_df[['userid', 'feedid'] + target]\n",
    "for idx, target_name in enumerate(target):\n",
    "    result_df['p'+target_name] = [i[0] for i in result]\n",
    "    \n",
    "score(result_df, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e96ca204",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
