{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "76e4c6e1",
   "metadata": {},
   "source": [
    "## Shared-Bottom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "35b33947",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import namedtuple\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.models import *\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.python.keras.callbacks import EarlyStopping\n",
    "from sklearn.preprocessing import  MinMaxScaler, LabelEncoder\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.metrics import classification_report, roc_curve"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beb5f83d",
   "metadata": {},
   "source": [
    "##### 获取数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "63e88863",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "各行为比例:  0.03501586934580252 0.02580487086290815 0.007533327266004016 0.0038211876059220415\n",
      "train_df.shape: (6708846, 13), test_df.shape: (609036, 13)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>videoplayseconds</th>\n",
       "      <th>userid</th>\n",
       "      <th>feedid</th>\n",
       "      <th>authorid</th>\n",
       "      <th>bgm_song_id</th>\n",
       "      <th>bgm_singer_id</th>\n",
       "      <th>manual_keyword_list</th>\n",
       "      <th>manual_tag_list</th>\n",
       "      <th>read_comment</th>\n",
       "      <th>like</th>\n",
       "      <th>click_avatar</th>\n",
       "      <th>forward</th>\n",
       "      <th>sample_weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1127727</th>\n",
       "      <td>3.091797</td>\n",
       "      <td>1288</td>\n",
       "      <td>1764</td>\n",
       "      <td>519</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>[661, 1299, 978, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
       "      <td>[34, 35, 9, 2, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4869098</th>\n",
       "      <td>2.996094</td>\n",
       "      <td>17244</td>\n",
       "      <td>4461</td>\n",
       "      <td>3881</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[40, 1215, 21, 113, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
       "      <td>[31, 32, 9, 33, 2, 3, 43, 0, 0, 0, 0]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6344229</th>\n",
       "      <td>4.007812</td>\n",
       "      <td>2404</td>\n",
       "      <td>0</td>\n",
       "      <td>1222</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[432, 516, 2598, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
       "      <td>[66, 55, 9, 2, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6354866</th>\n",
       "      <td>2.708984</td>\n",
       "      <td>8153</td>\n",
       "      <td>0</td>\n",
       "      <td>898</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[1, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1264072</th>\n",
       "      <td>2.833984</td>\n",
       "      <td>0</td>\n",
       "      <td>5103</td>\n",
       "      <td>303</td>\n",
       "      <td>994</td>\n",
       "      <td>236</td>\n",
       "      <td>[7, 8, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[12, 13, 9, 2, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         videoplayseconds  userid  feedid  authorid  bgm_song_id  \\\n",
       "1127727          3.091797    1288    1764       519            5   \n",
       "4869098          2.996094   17244    4461      3881            1   \n",
       "6344229          4.007812    2404       0      1222            0   \n",
       "6354866          2.708984    8153       0       898            1   \n",
       "1264072          2.833984       0    5103       303          994   \n",
       "\n",
       "         bgm_singer_id                                manual_keyword_list  \\\n",
       "1127727              5  [661, 1299, 978, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...   \n",
       "4869098              1  [40, 1215, 21, 113, 0, 0, 0, 0, 0, 0, 0, 0, 0,...   \n",
       "6344229              0  [432, 516, 2598, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...   \n",
       "6354866              1  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "1264072            236  [7, 8, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "\n",
       "                               manual_tag_list  read_comment  like  \\\n",
       "1127727    [34, 35, 9, 2, 0, 0, 0, 0, 0, 0, 0]             0     0   \n",
       "4869098  [31, 32, 9, 33, 2, 3, 43, 0, 0, 0, 0]             0     0   \n",
       "6344229    [66, 55, 9, 2, 0, 0, 0, 0, 0, 0, 0]             0     0   \n",
       "6354866      [1, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0]             0     0   \n",
       "1264072    [12, 13, 9, 2, 0, 0, 0, 0, 0, 0, 0]             0     0   \n",
       "\n",
       "         click_avatar  forward  sample_weight  \n",
       "1127727             0        0            0.0  \n",
       "4869098             0        0            0.0  \n",
       "6344229             0        0            0.0  \n",
       "6354866             0        0            0.0  \n",
       "1264072             0        0            0.0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_wechat_data():\n",
    "    \"\"\" 读取wechat数据集 \"\"\"\n",
    "    train_path = '../data/wechat/train_df.pkl'\n",
    "    test_path = '../data/wechat/test_df.pkl'\n",
    "    encoder_dict_path = '../data/wechat/encoder_dict.pkl'\n",
    "    train_df = pd.read_pickle(train_path)\n",
    "    test_df = pd.read_pickle(test_path)\n",
    "    encoder_dict = joblib.load(encoder_dict_path)\n",
    "    return train_df, test_df, encoder_dict\n",
    "\n",
    "train_df, test_df, encoder_dict = get_wechat_data()\n",
    "train_df = train_df.sample(frac=1.0)\n",
    "\n",
    "# 按行为比例加权\n",
    "data = pd.concat([train_df, test_df], axis=0)\n",
    "print('各行为比例: ', data.read_comment.sum() / data.shape[0], data.like.sum() / data.shape[0], data.click_avatar.sum() / data.shape[0], data.forward.sum() / data.shape[0])\n",
    "data['sample_weight'] = data['read_comment']*1.0+data['like']*1.1+data['click_avatar']*1.2+data['forward']*2.0\n",
    "\n",
    "train_df, test_df = data.iloc[:train_df.shape[0]], data.iloc[train_df.shape[0]:]\n",
    "print('train_df.shape: {}, test_df.shape: {}'.format(train_df.shape, test_df.shape))\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95f2d833",
   "metadata": {},
   "source": [
    "##### 模型构建"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "72f8106f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SparseFeature(name='userid', vocabulary_size=17390, embedding_size=8),\n",
       " SparseFeature(name='feedid', vocabulary_size=16448, embedding_size=8),\n",
       " SparseFeature(name='authorid', vocabulary_size=6966, embedding_size=8),\n",
       " SparseFeature(name='bgm_song_id', vocabulary_size=5773, embedding_size=8),\n",
       " SparseFeature(name='bgm_singer_id', vocabulary_size=4573, embedding_size=8),\n",
       " DenseFeature(name='videoplayseconds', dimension=1),\n",
       " VarLenSparseFeature(name='manual_keyword_list', vocabulary_size=21576, embedding_size=8, maxlen=18),\n",
       " VarLenSparseFeature(name='manual_tag_list', vocabulary_size=349, embedding_size=8, maxlen=11)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target = ['read_comment', 'like', 'click_avatar', 'forward']\n",
    "\n",
    "# 稠密特征、稀疏特征、变长稀疏特征\n",
    "dense_column_names = ['videoplayseconds']\n",
    "sparse_column_names = ['userid', 'feedid', 'authorid', 'bgm_song_id', 'bgm_singer_id']\n",
    "varlen_sparse_column_names = ['manual_keyword_list', 'manual_tag_list']\n",
    "\n",
    "SparseFeature = namedtuple('SparseFeature', ['name', 'vocabulary_size', 'embedding_size'])\n",
    "DenseFeature = namedtuple('DenseFeature', ['name', 'dimension'])\n",
    "VarLenSparseFeature = namedtuple('VarLenSparseFeature', ['name', 'vocabulary_size', 'embedding_size', 'maxlen'])\n",
    "\n",
    "varlen_sparse_column_maxlen_dict = {\n",
    "    'manual_keyword_list': 18,\n",
    "    'manual_tag_list': 11\n",
    "}\n",
    "\n",
    "feature_columns = [SparseFeature(f, vocabulary_size=data[f].nunique(), embedding_size=8) for f in sparse_column_names] + \\\n",
    "[DenseFeature(f, 1) for f in dense_column_names] + \\\n",
    "[VarLenSparseFeature(f, len(encoder_dict[f])+1, embedding_size=8, maxlen=varlen_sparse_column_maxlen_dict[f]) for f in varlen_sparse_column_names]\n",
    "feature_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "59f6d250",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "manual_keyword_list (InputLayer [(None, 18)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "manual_tag_list (InputLayer)    [(None, 11)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "userid (InputLayer)             [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "feedid (InputLayer)             [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "authorid (InputLayer)           [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "bgm_song_id (InputLayer)        [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "bgm_singer_id (InputLayer)      [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "var_emb_manual_keyword_list (Em (None, 18, 8)        172616      manual_keyword_list[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "var_emb_manual_tag_list (Embedd (None, 11, 8)        2800        manual_tag_list[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "emb_userid (Embedding)          (None, 1, 8)         139128      userid[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "emb_feedid (Embedding)          (None, 1, 8)         131592      feedid[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "emb_authorid (Embedding)        (None, 1, 8)         55736       authorid[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "emb_bgm_song_id (Embedding)     (None, 1, 8)         46192       bgm_song_id[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "emb_bgm_singer_id (Embedding)   (None, 1, 8)         36592       bgm_singer_id[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "masking (Masking)               (None, 18, 8)        0           var_emb_manual_keyword_list[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "masking_1 (Masking)             (None, 11, 8)        0           var_emb_manual_tag_list[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 8)            0           emb_userid[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 8)            0           emb_feedid[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "flatten_2 (Flatten)             (None, 8)            0           emb_authorid[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "flatten_3 (Flatten)             (None, 8)            0           emb_bgm_song_id[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_4 (Flatten)             (None, 8)            0           emb_bgm_singer_id[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "mean_pooling_layer (MeanPooling (None, 8)            0           masking[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "mean_pooling_layer_1 (MeanPooli (None, 8)            0           masking_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "videoplayseconds (InputLayer)   [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 40)           0           flatten[0][0]                    \n",
      "                                                                 flatten_1[0][0]                  \n",
      "                                                                 flatten_2[0][0]                  \n",
      "                                                                 flatten_3[0][0]                  \n",
      "                                                                 flatten_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 16)           0           mean_pooling_layer[0][0]         \n",
      "                                                                 mean_pooling_layer_1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 57)           0           videoplayseconds[0][0]           \n",
      "                                                                 concatenate[0][0]                \n",
      "                                                                 concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 8)            464         concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 8)            464         concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 8)            464         concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 8)            464         concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "read_comment (Dense)            (None, 1)            9           dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "like (Dense)                    (None, 1)            9           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "click_avatar (Dense)            (None, 1)            9           dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "forward (Dense)                 (None, 1)            9           dense_3[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 586,548\n",
      "Trainable params: 586,548\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "class MeanPoolingLayer(Layer):\n",
    "    def __init__(self, axis, **kwargs):\n",
    "        super(MeanPoolingLayer, self).__init__(**kwargs)\n",
    "        self.axis = axis\n",
    "        self.supports_masking = True\n",
    "    \n",
    "    def compute_mask(self, input, input_mask=None):\n",
    "        # need not to pass the mask to next layers\n",
    "        return None\n",
    "    \n",
    "    def call(self, x, mask=None):\n",
    "        if x is not None:\n",
    "            mask = K.cast(mask, K.floatx()) # (None, 18)\n",
    "            mask = K.repeat(mask, x.shape[-1]) # (None, 4, 18)\n",
    "            mask = tf.transpose(mask, [0, 2, 1]) # (None, 18, 4)\n",
    "            x = x * mask # # (None, 18, 4) * (None, 18, 4)\n",
    "            return K.sum(x, axis=self.axis) / K.sum(mask, axis=self.axis)\n",
    "        else:\n",
    "            return K.mean(x, axis=self.axis)\n",
    "\n",
    "def model_metric(prob, label, thr=0.5):\n",
    "    \"\"\" 模型评估 \"\"\"\n",
    "    # AUC\n",
    "    fpr, tpr, threshold = metrics.roc_curve(label, prob)\n",
    "    auc = metrics.auc(fpr, tpr)\n",
    "    score = metrics.accuracy_score(label, prob > thr)\n",
    "    # LogLoss\n",
    "    logloss = log_loss(label, prob)\n",
    "    print('模型准确率:{}, AUC得分:{}, LogLoss:{}'.format(score, auc, logloss))\n",
    "    print(classification_report(label, prob > thr, digits=2))\n",
    "    print('==========================================================')\n",
    "\n",
    "def build_input_layers(feature_columns):\n",
    "    \"\"\" 构建输入层 \"\"\"\n",
    "    dense_input_dict, sparse_input_dict, varlen_sparse_input_dict = {}, {}, {}\n",
    "    for f in feature_columns:\n",
    "        if isinstance(f, DenseFeature):\n",
    "            dense_input_dict[f.name] = Input(shape=(f.dimension, ), name=f.name)\n",
    "        elif isinstance(f, SparseFeature):\n",
    "            sparse_input_dict[f.name] = Input(shape=(1, ), name=f.name)\n",
    "        elif isinstance(f, VarLenSparseFeature):\n",
    "            varlen_sparse_input_dict[f.name] = Input(shape=(f.maxlen, ), name=f.name)\n",
    "    return dense_input_dict, sparse_input_dict, varlen_sparse_input_dict\n",
    "\n",
    "def build_embedding_layers(feature_columns):\n",
    "    \"\"\" 构建embedding层 \"\"\"\n",
    "    embedding_layer_dict = {}\n",
    "    for f in feature_columns:\n",
    "        if isinstance(f, SparseFeature):\n",
    "            embedding_layer_dict[f.name] = Embedding(f.vocabulary_size+1, f.embedding_size, name='emb_' + f.name)\n",
    "        elif isinstance(f, VarLenSparseFeature):\n",
    "            embedding_layer_dict[f.name] = Embedding(f.vocabulary_size+1, f.embedding_size, name='var_emb_' + f.name, mask_zero=True)\n",
    "    return embedding_layer_dict\n",
    "\n",
    "def embedding_lookup(columns, input_dict, embedding_layer_dict, flatten=False):\n",
    "    \"\"\" 根据feature_columns或column_names查表，得到对应embedding向量列表 \"\"\"\n",
    "    embedding_list = []\n",
    "    for f in columns:\n",
    "        if type(f) == str:\n",
    "            column_name = f\n",
    "        else:\n",
    "            column_name = f.name\n",
    "        _input = input_dict[column_name]\n",
    "        _embed = embedding_layer_dict[column_name]\n",
    "        embed_layer = _embed(_input)\n",
    "        if flatten:\n",
    "            embed_layer = Flatten()(embed_layer)\n",
    "        embedding_list.append(embed_layer)\n",
    "    return embedding_list\n",
    "\n",
    "def concat_input_list(input_list):\n",
    "    \"\"\" 合并input列表 \"\"\"\n",
    "    _num = len(input_list)\n",
    "    if _num > 1:\n",
    "        return Concatenate(axis=1)(input_list)\n",
    "    elif len(input_list) == 1:\n",
    "        return input_list[0]\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def SharedBottomModel(feature_columns, target):\n",
    "    \"\"\" 硬共享机制 \"\"\"\n",
    "    dense_input_dict, sparse_input_dict, varlen_sparse_input_dict = build_input_layers(feature_columns)\n",
    "    \n",
    "    # Input\n",
    "    input_list = list(dense_input_dict.values()) + list(sparse_input_dict.values()) + list(varlen_sparse_input_dict.values())\n",
    "    \n",
    "    # dense feature (input->concat)\n",
    "    concat_dense_input_list = concat_input_list(list(dense_input_dict.values()))\n",
    "    \n",
    "    # sparse feature (input->embed->concat)\n",
    "    embedding_layer_dict = build_embedding_layers(feature_columns)\n",
    "    sparse_feature_columns = list(filter(lambda x: isinstance(x, SparseFeature), feature_columns))\n",
    "    flatten_sparse_embed_list = embedding_lookup(sparse_feature_columns, sparse_input_dict, embedding_layer_dict, flatten=True)\n",
    "    concat_flatten_sparse_embed_list = concat_input_list(flatten_sparse_embed_list)\n",
    "    \n",
    "    # seq embeddings (input->embed->pooling->concat)\n",
    "    varlen_sparse_feature_columns = list(filter(lambda x: isinstance(x, VarLenSparseFeature), feature_columns))\n",
    "    varlen_sparse_embed_list = []\n",
    "    for f in varlen_sparse_feature_columns:\n",
    "        _input = varlen_sparse_input_dict[f.name] #  (None, 18)\n",
    "        _embed = embedding_layer_dict[f.name]\n",
    "        embed_layer = _embed(_input) # (None, 18, 4)\n",
    "        mask = Masking()(embed_layer) # (None, 18, 4)\n",
    "        mean_pooling_embed = MeanPoolingLayer(axis=1)(mask) # (None, 4)\n",
    "        varlen_sparse_embed_list.append(mean_pooling_embed)\n",
    "    concat_varlen_sparse_embed_list = concat_input_list(varlen_sparse_embed_list)\n",
    "    \n",
    "    # concat dense feature + concat sparse embeddings + concat seq embeddings\n",
    "    dnn_input = Concatenate(axis=1)([concat_dense_input_list, concat_flatten_sparse_embed_list, concat_varlen_sparse_embed_list])\n",
    "    \n",
    "    # 多个Tower结构\n",
    "    output_list = []\n",
    "    for target_name in target:\n",
    "        x = Dense(8, activation='relu')(dnn_input)\n",
    "        x = Dense(1, activation='sigmoid', name=target_name)(x)\n",
    "        output_list.append(x)\n",
    "    \n",
    "    model = Model(input_list, output_list)\n",
    "    return model\n",
    "\n",
    "model = SharedBottomModel(feature_columns, target)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8a8e01f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "5242/5242 [==============================] - 29s 5ms/step - loss: 0.2977 - read_comment_loss: 0.0983 - like_loss: 0.1160 - click_avatar_loss: 0.0463 - forward_loss: 0.0371 - read_comment_auc: 0.9163 - like_auc: 0.8029 - click_avatar_auc: 0.7509 - forward_auc: 0.6950 - val_loss: 0.2370 - val_read_comment_loss: 0.0905 - val_like_loss: 0.0907 - val_click_avatar_loss: 0.0357 - val_forward_loss: 0.0200 - val_read_comment_auc: 0.9349 - val_like_auc: 0.8551 - val_click_avatar_auc: 0.8293 - val_forward_auc: 0.8193\n",
      "Epoch 2/100\n",
      "5242/5242 [==============================] - 27s 5ms/step - loss: 0.2304 - read_comment_loss: 0.0885 - like_loss: 0.0884 - click_avatar_loss: 0.0345 - forward_loss: 0.0190 - read_comment_auc: 0.9392 - like_auc: 0.8711 - click_avatar_auc: 0.8615 - forward_auc: 0.8578 - val_loss: 0.2359 - val_read_comment_loss: 0.0902 - val_like_loss: 0.0905 - val_click_avatar_loss: 0.0355 - val_forward_loss: 0.0197 - val_read_comment_auc: 0.9354 - val_like_auc: 0.8568 - val_click_avatar_auc: 0.8303 - val_forward_auc: 0.8422\n",
      "Epoch 3/100\n",
      "5242/5242 [==============================] - 28s 5ms/step - loss: 0.2269 - read_comment_loss: 0.0875 - like_loss: 0.0874 - click_avatar_loss: 0.0337 - forward_loss: 0.0183 - read_comment_auc: 0.9412 - like_auc: 0.8766 - click_avatar_auc: 0.8742 - forward_auc: 0.8780 - val_loss: 0.2356 - val_read_comment_loss: 0.0903 - val_like_loss: 0.0904 - val_click_avatar_loss: 0.0353 - val_forward_loss: 0.0196 - val_read_comment_auc: 0.9356 - val_like_auc: 0.8572 - val_click_avatar_auc: 0.8427 - val_forward_auc: 0.8400\n",
      "Epoch 4/100\n",
      "5242/5242 [==============================] - 27s 5ms/step - loss: 0.2249 - read_comment_loss: 0.0868 - like_loss: 0.0868 - click_avatar_loss: 0.0332 - forward_loss: 0.0180 - read_comment_auc: 0.9425 - like_auc: 0.8794 - click_avatar_auc: 0.8805 - forward_auc: 0.8877 - val_loss: 0.2360 - val_read_comment_loss: 0.0902 - val_like_loss: 0.0907 - val_click_avatar_loss: 0.0354 - val_forward_loss: 0.0197 - val_read_comment_auc: 0.9354 - val_like_auc: 0.8569 - val_click_avatar_auc: 0.8383 - val_forward_auc: 0.8383\n",
      "Epoch 5/100\n",
      "5242/5242 [==============================] - 27s 5ms/step - loss: 0.2232 - read_comment_loss: 0.0862 - like_loss: 0.0864 - click_avatar_loss: 0.0329 - forward_loss: 0.0178 - read_comment_auc: 0.9437 - like_auc: 0.8817 - click_avatar_auc: 0.8853 - forward_auc: 0.8950 - val_loss: 0.2365 - val_read_comment_loss: 0.0903 - val_like_loss: 0.0907 - val_click_avatar_loss: 0.0356 - val_forward_loss: 0.0199 - val_read_comment_auc: 0.9344 - val_like_auc: 0.8569 - val_click_avatar_auc: 0.8359 - val_forward_auc: 0.8281\n",
      "Epoch 6/100\n",
      "5242/5242 [==============================] - 27s 5ms/step - loss: 0.2218 - read_comment_loss: 0.0857 - like_loss: 0.0860 - click_avatar_loss: 0.0325 - forward_loss: 0.0176 - read_comment_auc: 0.9448 - like_auc: 0.8838 - click_avatar_auc: 0.8896 - forward_auc: 0.9027 - val_loss: 0.2369 - val_read_comment_loss: 0.0904 - val_like_loss: 0.0908 - val_click_avatar_loss: 0.0358 - val_forward_loss: 0.0199 - val_read_comment_auc: 0.9347 - val_like_auc: 0.8567 - val_click_avatar_auc: 0.8363 - val_forward_auc: 0.8352\n",
      "Epoch 7/100\n",
      "5242/5242 [==============================] - 29s 6ms/step - loss: 0.2204 - read_comment_loss: 0.0851 - like_loss: 0.0856 - click_avatar_loss: 0.0323 - forward_loss: 0.0174 - read_comment_auc: 0.9458 - like_auc: 0.8860 - click_avatar_auc: 0.8923 - forward_auc: 0.9083 - val_loss: 0.2379 - val_read_comment_loss: 0.0908 - val_like_loss: 0.0911 - val_click_avatar_loss: 0.0358 - val_forward_loss: 0.0201 - val_read_comment_auc: 0.9324 - val_like_auc: 0.8559 - val_click_avatar_auc: 0.8361 - val_forward_auc: 0.8281\n",
      "Epoch 8/100\n",
      "5242/5242 [==============================] - 30s 6ms/step - loss: 0.2191 - read_comment_loss: 0.0847 - like_loss: 0.0852 - click_avatar_loss: 0.0319 - forward_loss: 0.0172 - read_comment_auc: 0.9467 - like_auc: 0.8879 - click_avatar_auc: 0.8957 - forward_auc: 0.9126 - val_loss: 0.2389 - val_read_comment_loss: 0.0910 - val_like_loss: 0.0913 - val_click_avatar_loss: 0.0363 - val_forward_loss: 0.0203 - val_read_comment_auc: 0.9324 - val_like_auc: 0.8555 - val_click_avatar_auc: 0.8229 - val_forward_auc: 0.8345\n",
      "Epoch 9/100\n",
      "5242/5242 [==============================] - 28s 5ms/step - loss: 0.2179 - read_comment_loss: 0.0842 - like_loss: 0.0849 - click_avatar_loss: 0.0317 - forward_loss: 0.0171 - read_comment_auc: 0.9475 - like_auc: 0.8897 - click_avatar_auc: 0.8984 - forward_auc: 0.9150 - val_loss: 0.2395 - val_read_comment_loss: 0.0911 - val_like_loss: 0.0918 - val_click_avatar_loss: 0.0363 - val_forward_loss: 0.0203 - val_read_comment_auc: 0.9325 - val_like_auc: 0.8531 - val_click_avatar_auc: 0.8282 - val_forward_auc: 0.8348\n",
      "Epoch 10/100\n",
      "5242/5242 [==============================] - 28s 5ms/step - loss: 0.2168 - read_comment_loss: 0.0837 - like_loss: 0.0846 - click_avatar_loss: 0.0314 - forward_loss: 0.0170 - read_comment_auc: 0.9483 - like_auc: 0.8912 - click_avatar_auc: 0.9007 - forward_auc: 0.9180 - val_loss: 0.2405 - val_read_comment_loss: 0.0914 - val_like_loss: 0.0918 - val_click_avatar_loss: 0.0367 - val_forward_loss: 0.0206 - val_read_comment_auc: 0.9323 - val_like_auc: 0.8534 - val_click_avatar_auc: 0.8221 - val_forward_auc: 0.8288\n",
      "Epoch 11/100\n",
      "5242/5242 [==============================] - 29s 5ms/step - loss: 0.2157 - read_comment_loss: 0.0833 - like_loss: 0.0843 - click_avatar_loss: 0.0312 - forward_loss: 0.0169 - read_comment_auc: 0.9490 - like_auc: 0.8927 - click_avatar_auc: 0.9028 - forward_auc: 0.9187 - val_loss: 0.2426 - val_read_comment_loss: 0.0921 - val_like_loss: 0.0928 - val_click_avatar_loss: 0.0369 - val_forward_loss: 0.0208 - val_read_comment_auc: 0.9301 - val_like_auc: 0.8514 - val_click_avatar_auc: 0.8201 - val_forward_auc: 0.8260\n",
      "Epoch 12/100\n",
      "5242/5242 [==============================] - 28s 5ms/step - loss: 0.2148 - read_comment_loss: 0.0829 - like_loss: 0.0840 - click_avatar_loss: 0.0309 - forward_loss: 0.0169 - read_comment_auc: 0.9498 - like_auc: 0.8940 - click_avatar_auc: 0.9054 - forward_auc: 0.9207 - val_loss: 0.2434 - val_read_comment_loss: 0.0924 - val_like_loss: 0.0927 - val_click_avatar_loss: 0.0371 - val_forward_loss: 0.0211 - val_read_comment_auc: 0.9295 - val_like_auc: 0.8511 - val_click_avatar_auc: 0.8169 - val_forward_auc: 0.8320\n",
      "Epoch 13/100\n",
      "5242/5242 [==============================] - 29s 5ms/step - loss: 0.2138 - read_comment_loss: 0.0826 - like_loss: 0.0838 - click_avatar_loss: 0.0307 - forward_loss: 0.0168 - read_comment_auc: 0.9503 - like_auc: 0.8953 - click_avatar_auc: 0.9074 - forward_auc: 0.9230 - val_loss: 0.2447 - val_read_comment_loss: 0.0927 - val_like_loss: 0.0935 - val_click_avatar_loss: 0.0373 - val_forward_loss: 0.0211 - val_read_comment_auc: 0.9285 - val_like_auc: 0.8489 - val_click_avatar_auc: 0.8219 - val_forward_auc: 0.8318\n",
      "Epoch 00013: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1ca26d74e10>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 模型训练\n",
    "train_input = {f: np.array([row for row in train_df[f]]) for f in dense_column_names + sparse_column_names + varlen_sparse_column_names}\n",
    "test_input = {f: np.array([row for row in test_df[f]]) for f in dense_column_names + sparse_column_names + varlen_sparse_column_names}\n",
    "\n",
    "my_callbacks = [\n",
    "    EarlyStopping(monitor='val_loss', patience=10, verbose=2, mode='auto')\n",
    "]\n",
    "\n",
    "loss = tf.keras.losses.binary_crossentropy\n",
    "model.compile('adam',\n",
    "              loss={'read_comment': loss, 'like': loss, 'click_avatar': loss, 'forward': loss},\n",
    "              metrics=tf.keras.metrics.AUC(name='auc'))\n",
    "\n",
    "# 多个任务\n",
    "y_list = [train_df[i].values for i in target]\n",
    "model.fit(x=train_input,\n",
    "          y=y_list,\n",
    "          batch_size=1024,\n",
    "          epochs=100,\n",
    "          validation_split=0.2,\n",
    "          callbacks=my_callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fe60f097",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 read_comment\n",
      "模型准确率:0.9661169454679198, AUC得分:0.9159227500415765, LogLoss:0.10048442053604158\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.99      0.98    588439\n",
      "           1       0.50      0.21      0.30     20597\n",
      "\n",
      "    accuracy                           0.97    609036\n",
      "   macro avg       0.74      0.60      0.64    609036\n",
      "weighted avg       0.96      0.97      0.96    609036\n",
      "\n",
      "==========================================================\n",
      "1 like\n",
      "模型准确率:0.9761984513230745, AUC得分:0.8140981442454559, LogLoss:0.09704677710581265\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99    594422\n",
      "           1       0.53      0.08      0.14     14614\n",
      "\n",
      "    accuracy                           0.98    609036\n",
      "   macro avg       0.75      0.54      0.56    609036\n",
      "weighted avg       0.97      0.98      0.97    609036\n",
      "\n",
      "==========================================================\n",
      "2 click_avatar\n",
      "模型准确率:0.9922812444584557, AUC得分:0.8013360952050113, LogLoss:0.04262523673125922\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00    604496\n",
      "           1       0.17      0.01      0.02      4540\n",
      "\n",
      "    accuracy                           0.99    609036\n",
      "   macro avg       0.58      0.50      0.51    609036\n",
      "weighted avg       0.99      0.99      0.99    609036\n",
      "\n",
      "==========================================================\n",
      "3 forward\n",
      "模型准确率:0.9965584957211068, AUC得分:0.8359446471162835, LogLoss:0.021509609143312302\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    606975\n",
      "           1       0.19      0.01      0.01      2061\n",
      "\n",
      "    accuracy                           1.00    609036\n",
      "   macro avg       0.59      0.50      0.50    609036\n",
      "weighted avg       0.99      1.00      0.99    609036\n",
      "\n",
      "==========================================================\n"
     ]
    }
   ],
   "source": [
    "# 模型预测与评估\n",
    "result = model.predict(test_input)\n",
    "\n",
    "for idx, target_name in enumerate(target):\n",
    "    print(idx, target_name)\n",
    "    model_metric(np.array([i[0] for i in result[idx]]), test_df[target_name].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f727c792",
   "metadata": {},
   "source": [
    "##### 不同行为加权gAUC分数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0d3049ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\SoftwareInstall\\Anaconda\\envs\\py36\\lib\\site-packages\\ipykernel_launcher.py:75: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "action:  read_comment\n",
      "action:  like\n",
      "action:  click_avatar\n",
      "action:  forward\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'score': 0.6244,\n",
       " 'score_detail': {'read_comment': 0.6107182126500414,\n",
       "  'like': 0.5928657623936008,\n",
       "  'click_avatar': 0.6774111449414262,\n",
       "  'forward': 0.6682032427454121}}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.stats import rankdata\n",
    "from collections import defaultdict\n",
    "\n",
    "def fast_auc(actual, predicted):\n",
    "    # https://www.kaggle.com/c/riiid-test-answer-prediction/discussion/208031    \n",
    "    pred_ranks = rankdata(predicted)\n",
    "    n_pos = np.sum(actual)\n",
    "    n_neg = len(actual) - n_pos\n",
    "    return (np.sum(pred_ranks[actual == 1]) - n_pos*(n_pos+1)/2) / (n_pos*n_neg)\n",
    "\n",
    "def uAUC(labels, preds, users):\n",
    "    \"\"\" 计算uAUC \"\"\"\n",
    "    label_dict, pred_dict, user_flag_dict = defaultdict(lambda: []), defaultdict(lambda: []), defaultdict(lambda: False)\n",
    "    for idx, label in enumerate(labels):\n",
    "        user = users[idx]\n",
    "        pred = preds[idx]\n",
    "        label = labels[idx]\n",
    "        label_dict[user].append(label)\n",
    "        pred_dict[user].append(pred)\n",
    "    \n",
    "    # 当前用户是否全为正/负样本\n",
    "    for user in set(users):\n",
    "        _labels = label_dict[user]\n",
    "        flag = False\n",
    "        for i in range(len(_labels)-1):\n",
    "            if _labels[i] != _labels[i+1]:\n",
    "                flag = True\n",
    "                break\n",
    "        user_flag_dict[user] = flag\n",
    "    \n",
    "    auc_sum = 0.0\n",
    "    auc_cnt = 0.0\n",
    "    for user in user_flag_dict:\n",
    "        if user_flag_dict[user]:\n",
    "            auc = fast_auc(np.asarray(label_dict[user]), np.asarray(pred_dict[user]))\n",
    "            auc_sum += auc\n",
    "            auc_cnt += 1.0\n",
    "    return auc_sum * 1.0 / auc_cnt\n",
    "\n",
    "def score(result_df, action_list):\n",
    "    \"\"\" 计算多个行为的加权gAUC分数 \"\"\"\n",
    "    weight_dict = {\n",
    "        \"read_comment\": 4.0,  # 是否查看评论\n",
    "        \"like\": 3.0,  # 是否点赞\n",
    "        \"click_avatar\": 2.0,  # 是否点击头像\n",
    "        \"forward\": 1.0,  # 是否转发\n",
    "        \"favorite\": 1.0,  # 是否收藏\n",
    "        \"comment\": 1.0,  # 是否发表评论\n",
    "        \"follow\": 1.0  # 是否关注\n",
    "    }\n",
    "    \n",
    "    score = 0.0\n",
    "    score_dict = {}\n",
    "    weight_sum = 0.0\n",
    "    for action in action_list:\n",
    "        print('action: ', action)\n",
    "        labels = result_df[action].values\n",
    "        preds = result_df['p'+action].values\n",
    "        users = result_df['userid'].values\n",
    "        weight = weight_dict[action]\n",
    "        gauc = uAUC(labels, preds, users)\n",
    "        score_dict[action] = gauc\n",
    "        score += weight * gauc\n",
    "        weight_sum += weight\n",
    "    \n",
    "    score /= weight_sum\n",
    "    score = round(score, 4)\n",
    "    return {\n",
    "        'score': score,\n",
    "        'score_detail': score_dict\n",
    "    }\n",
    "\n",
    "result_df = test_df[['userid', 'feedid'] + target]\n",
    "for idx, target_name in enumerate(target):\n",
    "    result_df['p'+target_name] = [i[0] for i in result[idx]]\n",
    "\n",
    "score(result_df, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e413301",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
